{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Micro Controller Benchmark\n",
    "\n",
    "Benchmark PyTorch Models and generate Compatibility list for micro controllers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "# %pip install torch torchaudio omegaconf soundfile numpy prettytable transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\hws\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import wave\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from glob import glob\n",
    "from timeit import default_timer\n",
    "from typing import TypedDict, Callable\n",
    "from prettytable import PrettyTable\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from transformers import AutoProcessor, HubertForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "\n",
    "class Model(TypedDict):\n",
    "    name: str\n",
    "    num_inferred_samples: int\n",
    "    infer: Callable[[None], list[str]]\n",
    "\n",
    "class MicroController(TypedDict):\n",
    "    name: str\n",
    "    architecture: str\n",
    "    memory_mb: float\n",
    "    cpu_speed_ghz: float\n",
    "\n",
    "class ModelResults:\n",
    "    name: str\n",
    "    cpu_time_total_ms: float\n",
    "    mean_inference_time_ms: float\n",
    "    mean_memory_usage_mb: float\n",
    "    m_flops: float\n",
    "    samples_per_cpu_second: float\n",
    "    samples_per_inference_second: float\n",
    "\n",
    "class ModelMicroControllerResults:\n",
    "    model_name: str\n",
    "    estimated_cpu_time_total_ms: float\n",
    "    estimated_inference_time_ms: float\n",
    "    estimated_samples_per_cpu_second: float\n",
    "    estimated_samples_per_inference_second: float\n",
    "    memory_usage_percentage: float\n",
    "    compatible: bool\n",
    "\n",
    "class BenchmarkOptions:\n",
    "    cpu_speed_ghz: float\n",
    "    target_sampling_rate_khz: float\n",
    "    logfile_path: str\n",
    "\n",
    "Log = Callable[[str], None]\n",
    "\n",
    "CreateModel = Callable[[None], Model]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_mb(byte: int) -> int:\n",
    "    return byte / (1024 ** 2)\n",
    "\n",
    "def create_logger(logifle_path: str) -> Log:\n",
    "    def __log(msg: str):\n",
    "        with open(logifle_path, 'a') as f:\n",
    "            f.write(f'{msg}\\n' )\n",
    "        print(msg)\n",
    "    return __log\n",
    "\n",
    "def log_hash_comment(content: str, log: Log):\n",
    "    content_str = f'# {content} #'\n",
    "    num_hashes = len(content_str)\n",
    "    hashes = '#' * num_hashes\n",
    "    log(\n",
    "        f'{hashes}\\n'\n",
    "        f'{content_str}\\n'\n",
    "        f'{hashes}\\n'\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(create_model: CreateModel, options: BenchmarkOptions, log: Log, row_limit = 5, iterations = 5) -> ModelResults:\n",
    "\n",
    "    #####################\n",
    "    # Instantiate Model #\n",
    "    #####################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ########################\n",
    "    # Run PyTorch Profiler #\n",
    "    ########################\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], profile_memory=True, with_flops=True, record_shapes=True, with_stack=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            _out = model['infer']()\n",
    "\n",
    "    key_averages = prof.key_averages()\n",
    "    total_average = key_averages.total_average()\n",
    "\n",
    "    key_averages.table()\n",
    "\n",
    "    cpu_time_ms = total_average.cpu_time_total * 0.001\n",
    "    self_cpu_time_ms = total_average.self_cpu_time_total * 0.001\n",
    "    cpu_memory_usage_mb = byte_to_mb(total_average.cpu_memory_usage)\n",
    "    self_cpu_memory_usage_mb = byte_to_mb(total_average.self_cpu_memory_usage)\n",
    "    m_flops = total_average.flops * 0.000001\n",
    "\n",
    "    log(f'--- PyTorch Profile: {model_name} ---\\n')\n",
    "\n",
    "\n",
    "    log(\n",
    "        f'CPU time top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_time_total\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'CPU memory usage top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_memory_usage\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'MFLOPs top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"flops\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'Total averages\\n'\n",
    "        f'CPU time total [ms]: {cpu_time_ms}\\n' \n",
    "        f'Self CPU time total [ms]: {self_cpu_time_ms}\\n'\n",
    "        f'CPU memory usage [Mb]: {cpu_memory_usage_mb}\\n'\n",
    "        f'Self CPU memory usage [Mb]: {self_cpu_memory_usage_mb}\\n'\n",
    "        f'MFLOPs: {m_flops}\\n'\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([cpu_memory_usage_mb, mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))\n",
    "    samples_per_cpu_second = num_samples / (self_cpu_time_ms * 0.001)\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': self_cpu_time_ms,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': m_flops,\n",
    "        'samples_per_cpu_second': samples_per_cpu_second,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per CPU second: {samples_per_cpu_second}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "    )\n",
    "\n",
    "    # Delete model before next benchmark\n",
    "    del model\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model_micro_controller(model_results: ModelResults, micro_controller: MicroController, options: BenchmarkOptions) -> ModelMicroControllerResults:\n",
    "    controller_cpu_speed_ghz = micro_controller['cpu_speed_ghz']\n",
    "    benchmark_cpu_speed_ghz = options['cpu_speed_ghz']\n",
    "    cpu_time_factor = benchmark_cpu_speed_ghz / controller_cpu_speed_ghz\n",
    "\n",
    "    estimated_cpu_time_total_ms = model_results['cpu_time_total_ms'] * cpu_time_factor\n",
    "    estimated_inference_time_ms = model_results['mean_inference_time_ms'] * cpu_time_factor\n",
    "\n",
    "    estimated_samples_per_cpu_second = model_results['samples_per_cpu_second'] / cpu_time_factor\n",
    "    estimated_samples_per_inference_second = model_results['samples_per_inference_second'] / cpu_time_factor\n",
    "\n",
    "    memory_usage_percentage = (model_results['mean_memory_usage_mb'] / micro_controller['memory_mb']) * 100\n",
    "\n",
    "    target_sampling_rate_hz = options['target_sampling_rate_khz'] * 1000\n",
    "\n",
    "    compatible = (\n",
    "        estimated_samples_per_cpu_second >= target_sampling_rate_hz \n",
    "        and estimated_samples_per_inference_second >= target_sampling_rate_hz\n",
    "        and memory_usage_percentage <= 100\n",
    "    )\n",
    "\n",
    "    results: ModelMicroControllerResults = {\n",
    "        'model_name': model_results['name'],\n",
    "        'estimated_cpu_time_total_ms': estimated_cpu_time_total_ms,\n",
    "        'estimated_inference_time_ms': estimated_inference_time_ms,\n",
    "        'estimated_samples_per_cpu_second': estimated_samples_per_cpu_second,\n",
    "        'estimated_samples_per_inference_second': estimated_samples_per_inference_second,\n",
    "        'memory_usage_percentage': memory_usage_percentage,\n",
    "        'compatible': compatible,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(create_models: list[CreateModel], micro_controllers: list[MicroController], options: BenchmarkOptions):\n",
    "    ##################\n",
    "    # Create logfile #\n",
    "    ##################\n",
    "\n",
    "    logfile_path = options['logfile_path']\n",
    "    f = open(logfile_path, 'w')\n",
    "    f.close()\n",
    "\n",
    "    log = create_logger(logfile_path)\n",
    "\n",
    "    ###############################\n",
    "    # Benchmark individual models #\n",
    "    ###############################\n",
    "\n",
    "    log(\n",
    "        f'--- Benchmarking {len(create_models)} models ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "    models_results = [benchmark_model(create_model, options, log) for create_model in create_models]\n",
    "\n",
    "    ##########################################\n",
    "    # Benchmark models for micro controllers #\n",
    "    ##########################################\n",
    "\n",
    "    log(\n",
    "        f'\\n--- Benchmarking {len(create_models)} models for {len(micro_controllers)} micro controllers ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    for micro_controller in micro_controllers:\n",
    "        log_hash_comment(micro_controller['name'], log)\n",
    "        log(\n",
    "            'Info\\n'\n",
    "            f'Architecture: {micro_controller[\"architecture\"]}\\n'\n",
    "            f'Memory [Mb]: {micro_controller[\"memory_mb\"]}\\n'\n",
    "            f'CPU speed [GHz]: {micro_controller[\"cpu_speed_ghz\"]}\\n'\n",
    "        )\n",
    "        table = PrettyTable(\n",
    "            ['Model', 'Estimated CPU time [ms]', 'Estimated inference time [ms]', 'Estimated samples per CPU second', 'Estimated samples per inference second', 'Memory usage %', 'COMPATIBLE']\n",
    "        )\n",
    "        results = [benchmark_model_micro_controller(model_result, micro_controller, options).values() for model_result in models_results]\n",
    "        table.add_rows(results)\n",
    "        log(table.get_string())\n",
    "        log('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret PyTorch Profiler results\n",
    "\n",
    "References:\n",
    "- [Recipe](https://h-huang.github.io/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "\n",
    "#### CPU time\n",
    "\n",
    "CPU time vs self CPU time: operators can call other operators -> self cpu time excludes time spent in children operator calls, while total cpu time includes it\n",
    "\n",
    "#### Memory usage\n",
    "\n",
    "- Shows amount of memory used by the model’s tensors:\n",
    "- That was allocated (or released) during the execution of the model’s operators\n",
    "\n",
    "Self memory: corresponds to the memory allocated (released) by the operator, excluding the children calls to the other operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch SILERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Moritz/.cache\\torch\\hub\\snakers4_silero-models_master\n",
      "100%|██████████| 0.99M/0.99M [00:01<00:00, 551kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Input statistics ---\n",
      "Sampling rate: 48000 Hz\n",
      "Number of samples: 518400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Use SILERO utils to download model and test file #\n",
    "####################################################\n",
    "\n",
    "# Always use CPU (simulate run on micro controller)\n",
    "device = torch.device('cpu')  \n",
    "\n",
    "# Download model, decoder and utils\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device\n",
    ")\n",
    "(read_batch, split_into_batches, _ , prepare_model_input) = utils  # see function signature for details\n",
    "\n",
    "# Download a single test file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n",
    "                            dst ='speech_orig.wav', progress=True)\n",
    "test_files = glob('speech_orig.wav')\n",
    "\n",
    "######################################\n",
    "# Get number of samples in test data #\n",
    "######################################\n",
    "\n",
    "audio_file = wave.open(test_files[0], 'r')\n",
    "sampling_rate = audio_file.getframerate()\n",
    "num_samples = audio_file.getnframes()\n",
    "\n",
    "print(\n",
    "    f'\\n--- Input statistics ---\\n'\n",
    "    f'Sampling rate: {sampling_rate} Hz\\n'\n",
    "    f'Number of samples: {num_samples}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the boch canoe slit on the smooth planks blew the sheet to the dark blue background it's easy to tell a depth of a well four hours of steady work faced us\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create SILERO model #\n",
    "#######################\n",
    "\n",
    "def create_silero_model():\n",
    "    # Prepare input data\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "    input = prepare_model_input(read_batch(batches[0]),\n",
    "                                device=device)\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_silero():\n",
    "        output = model(input)\n",
    "        return [decoder(example.cpu()) for example in output]\n",
    "\n",
    "    silero_model: Model = {\n",
    "        'name': 'SILERO',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_silero,\n",
    "    }\n",
    "\n",
    "    return silero_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "silero_model = create_silero_model()\n",
    "transcription = silero_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del silero_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuBERT\n",
    "\n",
    "Reference: [Hugging Face](https://huggingface.co/docs/transformers/model_doc/hubert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"THE BIRCH CANOE SLID ON THE SMOOTH PLANKS GLUE THE SHEET TO THE DARK BLUE BACKGROUND IT'S EASY TO TELL THE DEPTH OF A WELL FOUR HOURS OF STEADY WORK FACED US\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create HuBERT model #\n",
    "#######################\n",
    "\n",
    "def create_hubert_model():\n",
    "    # Download model\n",
    "    model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "    # Prepare inputs\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "    inputs = processor(read_batch(batches[0])[0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_hubert():\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        return processor.batch_decode(predicted_ids)\n",
    "\n",
    "    hubert_model: Model = {\n",
    "        'name': 'HuBERT',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_hubert,\n",
    "    }\n",
    "\n",
    "    return hubert_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "hubert_model = create_hubert_model()\n",
    "transcription = hubert_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del hubert_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro Controllers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "esp32: MicroController = {\n",
    "    'name': 'ESP32',\n",
    "    'architecture': '32-bit RISC-V',\n",
    "    'cpu_speed_ghz': 0.24,\n",
    "    'memory_mb': 0.23,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_zero: MicroController = {\n",
    "    'name': 'Raspberry Pi Zero v1.3',\n",
    "    'architecture': '32-bit ARM',\n",
    "    'cpu_speed_ghz': 1,\n",
    "    'memory_mb': 512,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_3_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 3 B v1.2',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.2,\n",
    "    'memory_mb': 1000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Benchmarking 2 models ---\n",
      "\n",
      "\n",
      "##########\n",
      "# SILERO #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: SILERO ---\n",
      "\n",
      "CPU time top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "               model_inference        66.07%     498.652ms       100.00%     754.709ms     754.709ms           0 b    -533.01 Kb             1            --  \n",
      "                       forward         2.55%      19.239ms        33.50%     252.810ms     252.810ms     530.72 Kb     -54.92 Mb             1            --  \n",
      "                  aten::linear         0.62%       4.670ms        14.30%     107.914ms       1.686ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "                   aten::addmm        12.65%      95.497ms        13.33%     100.635ms       1.572ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::conv1d         0.21%       1.576ms         6.45%      48.654ms       2.027ms      10.56 Mb     -10.57 Mb            24            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 754.709ms\n",
      "\n",
      "CPU memory usage top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::empty         0.10%     721.000us         0.10%     721.000us       2.943us      74.46 Mb      74.46 Mb           245            --  \n",
      "              aten::empty_like         0.17%       1.274ms         0.20%       1.524ms      15.394us      40.00 Mb       1.06 Mb            99            --  \n",
      "                   aten::clone         0.35%       2.641ms         1.29%       9.737ms      99.357us      39.34 Mb    -816.00 Kb            98            --  \n",
      "                   aten::addmm        12.65%      95.497ms        13.33%     100.635ms       1.572ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::linear         0.62%       4.670ms        14.30%     107.914ms       1.686ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 754.709ms\n",
      "\n",
      "MFLOPs top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::addmm        12.65%      95.497ms        13.33%     100.635ms       1.572ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                     aten::bmm         2.17%      16.372ms         2.17%      16.372ms     511.625us      11.97 Mb      11.97 Mb            32      1506.296  \n",
      "                     aten::add         0.63%       4.777ms         0.63%       4.777ms      65.438us     -14.87 Mb     -14.87 Mb            73         9.058  \n",
      "                     aten::mul         0.44%       3.307ms         0.45%       3.410ms      50.147us      14.04 Mb      14.04 Mb            68         7.188  \n",
      "               model_inference        66.07%     498.652ms       100.00%     754.709ms     754.709ms           0 b    -533.01 Kb             1            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 754.709ms\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 1558.193\n",
      "Self CPU time total [ms]: 754.7090000000001\n",
      "CPU memory usage [Mb]: 352.52447032928467\n",
      "Self CPU memory usage [Mb]: 0.0\n",
      "MFLOPs: 11765.032691999999\n",
      "\n",
      "--- Psutil memory_full_info: SILERO ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 478.10390625\n",
      "Std RSS: 1.8703125\n",
      "Mean USS [Mb]: 428.07578125\n",
      "Std USS: 1.6687500000000002\n",
      "\n",
      "--- Timeit default_timer: SILERO ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 198.56006000190973\n",
      "Std inference time: 1.2059412977497708\n",
      "\n",
      "--- Overall results: SILERO ---\n",
      "\n",
      "Mean memory usage [Mb]: 302.0600078978444\n",
      "Samples per CPU second: 686887.263832815\n",
      "Samples per inference second: 2610796.9548106203\n",
      "\n",
      "##########\n",
      "# HuBERT #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: HuBERT ---\n",
      "\n",
      "CPU time top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference         6.67%     275.795ms       100.00%        4.132s        4.132s      32.00 Mb      -2.79 Gb             1            --  \n",
      "                    aten::linear         0.14%       5.766ms        61.14%        2.526s      17.303ms     456.95 Mb           0 b           146            --  \n",
      "                     aten::addmm        59.72%        2.467s        60.87%        2.515s      17.227ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                    aten::conv1d         0.00%      89.000us        12.41%     512.651ms      64.081ms     136.04 Mb           0 b             8            --  \n",
      "               aten::convolution         0.00%     135.000us        12.41%     512.562ms      64.070ms     136.04 Mb           0 b             8            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.132s\n",
      "\n",
      "CPU memory usage top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::empty         0.10%       4.310ms         0.10%       4.310ms      14.272us     878.48 Mb     878.48 Mb           302            --  \n",
      "                       aten::add         1.54%      63.764ms         1.54%      63.764ms     797.050us     528.74 Mb     528.74 Mb            80       138.605  \n",
      "                aten::empty_like         0.01%     531.000us         0.08%       3.292ms      29.133us     503.05 Mb       2.11 Mb           113            --  \n",
      "                       aten::bmm         6.17%     254.756ms         6.17%     254.764ms       5.308ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                     aten::clone         0.02%     940.000us         3.59%     148.475ms       1.350ms     471.04 Mb      -2.11 Mb           110            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.132s\n",
      "\n",
      "MFLOPs top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::addmm        59.72%        2.467s        60.87%        2.515s      17.227ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                       aten::bmm         6.17%     254.756ms         6.17%     254.764ms       5.308ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                       aten::add         1.54%      63.764ms         1.54%      63.764ms     797.050us     528.74 Mb     528.74 Mb            80       138.605  \n",
      "                       aten::mul         0.20%       8.100ms         0.21%       8.671ms     346.840us      50.53 Mb      50.53 Mb            25        13.247  \n",
      "                 model_inference         6.67%     275.795ms       100.00%        4.132s        4.132s      32.00 Mb      -2.79 Gb             1            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.132s\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 12760.207\n",
      "Self CPU time total [ms]: 4131.859\n",
      "CPU memory usage [Mb]: 6604.431214332581\n",
      "Self CPU memory usage [Mb]: 32.0\n",
      "MFLOPs: 354856.833954\n",
      "\n",
      "--- Psutil memory_full_info: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 1711.5015625\n",
      "Std RSS: 0.6869031500146145\n",
      "Mean USS [Mb]: 1664.5390625\n",
      "Std USS: 0.41025668413201993\n",
      "\n",
      "--- Timeit default_timer: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 4129.226859996561\n",
      "Std inference time: 63.84358329110227\n",
      "\n",
      "--- Overall results: HuBERT ---\n",
      "\n",
      "Mean memory usage [Mb]: 1125.3489744921412\n",
      "Samples per CPU second: 125464.10707625792\n",
      "Samples per inference second: 125544.08308785237\n",
      "\n",
      "\n",
      "--- Benchmarking 2 models for 3 micro controllers ---\n",
      "\n",
      "\n",
      "#########\n",
      "# ESP32 #\n",
      "#########\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit RISC-V\n",
      "Memory [Mb]: 0.23\n",
      "CPU speed [GHz]: 0.24\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %  | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| SILERO |    11635.097083333336   |       3061.134258362775       |        44554.84954591232         |           169348.9916633916            | 131330.4382164541 |   False    |\n",
      "| HuBERT |    63699.49291666668    |       63658.91409161365       |        8138.212350892405         |            8143.39998407691            |  489282.16282267  |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "\n",
      "\n",
      "##########################\n",
      "# Raspberry Pi Zero v1.3 #\n",
      "##########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit ARM\n",
      "Memory [Mb]: 512\n",
      "CPU speed [GHz]: 1\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    2792.4233000000004   |        734.672222007066       |        185645.20644130133        |           705620.7985974649            | 58.996095292547736 |    True    |\n",
      "| HuBERT |    15287.878300000002   |       15278.139381987276      |        33909.218128718356        |           33930.83326698712            | 219.79472158049634 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "#########################\n",
      "# Raspberry Pi 3 B v1.2 #\n",
      "#########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 1000\n",
      "CPU speed [GHz]: 1.2\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    2327.019416666667    |       612.2268516725551       |        222774.2477295616         |           846744.9583169579            | 30.206000789784436 |    True    |\n",
      "| HuBERT |    12739.898583333335   |       12731.78281832273       |        40691.061754462025        |           40716.99992038455            | 112.53489744921413 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# Register models and micro controllers #\n",
    "#########################################\n",
    "\n",
    "models: list[Model] = [create_silero_model, create_hubert_model]\n",
    "\n",
    "micro_controllers: list[MicroController] = [esp32, pi_zero, pi_3_b]\n",
    "\n",
    "#########################\n",
    "# Set benchmark options #\n",
    "#########################\n",
    "\n",
    "benchmark_options: BenchmarkOptions = {\n",
    "    'cpu_speed_ghz': 3.7,\n",
    "    'target_sampling_rate_khz': 16,\n",
    "    'logfile_path': 'benchmark.txt'\n",
    "}\n",
    "\n",
    "#################\n",
    "# Run benchmark #\n",
    "#################\n",
    "\n",
    "benchmark(models, micro_controllers, benchmark_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
