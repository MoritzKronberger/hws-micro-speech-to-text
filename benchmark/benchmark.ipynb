{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Micro Controller Benchmark\n",
    "\n",
    "Benchmark PyTorch Models and generate Compatibility list for micro controllers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "# %pip install torch torchaudio omegaconf soundfile numpy prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import wave\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from timeit import default_timer\n",
    "from typing import TypedDict, Callable\n",
    "from prettytable import PrettyTable\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "\n",
    "class Model(TypedDict):\n",
    "    name: str\n",
    "    num_inferred_samples: int\n",
    "    infer: callable\n",
    "\n",
    "class MicroController(TypedDict):\n",
    "    name: str\n",
    "    architecture: str\n",
    "    memory_mb: float\n",
    "    cpu_speed_ghz: float\n",
    "\n",
    "class ModelResults:\n",
    "    name: str\n",
    "    cpu_time_total_ms: float\n",
    "    mean_inference_time_ms: float\n",
    "    mean_memory_usage_mb: float\n",
    "    m_flops: float\n",
    "    samples_per_cpu_second: float\n",
    "    samples_per_inference_second: float\n",
    "\n",
    "class ModelMicroControllerResults:\n",
    "    model_name: str\n",
    "    estimated_cpu_time_total_ms: float\n",
    "    estimated_inference_time_ms: float\n",
    "    estimated_samples_per_cpu_second: float\n",
    "    estimated_samples_per_inference_second: float\n",
    "    memory_usage_percentage: float\n",
    "    compatible: bool\n",
    "\n",
    "class BenchmarkOptions:\n",
    "    cpu_speed_ghz: float\n",
    "    target_sampling_rate_khz: float\n",
    "    logfile_path: str\n",
    "\n",
    "Log = Callable[[str], None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_mb(byte: int) -> int:\n",
    "    return byte / (1024 ** 2)\n",
    "\n",
    "def create_logger(logifle_path: str) -> Log:\n",
    "    def __log(msg: str):\n",
    "        with open(logifle_path, 'a') as f:\n",
    "            f.write(f'{msg}\\n' )\n",
    "        print(msg)\n",
    "    return __log\n",
    "\n",
    "def log_hash_comment(content: str, log: Log):\n",
    "    content_str = f'# {content} #'\n",
    "    num_hashes = len(content_str)\n",
    "    hashes = '#' * num_hashes\n",
    "    log(\n",
    "        f'{hashes}\\n'\n",
    "        f'{content_str}\\n'\n",
    "        f'{hashes}\\n'\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model: Model, options: BenchmarkOptions, log: Log, row_limit = 5, iterations = 10) -> ModelResults:\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    cpu_speed_ghz = options['cpu_speed_ghz']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ########################\n",
    "    # Run PyTorch Profiler #\n",
    "    ########################\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], profile_memory=True, with_flops=True, record_shapes=True, with_stack=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            _out = infer()\n",
    "\n",
    "    key_averages = prof.key_averages()\n",
    "    total_average = key_averages.total_average()\n",
    "\n",
    "    key_averages.table()\n",
    "\n",
    "    cpu_time_ms = total_average.cpu_time_total * 0.001\n",
    "    self_cpu_time_ms = total_average.self_cpu_time_total * 0.001\n",
    "    cpu_memory_usage_mb = byte_to_mb(total_average.cpu_memory_usage)\n",
    "    self_cpu_memory_usage_mb = byte_to_mb(total_average.self_cpu_memory_usage)\n",
    "    m_flops = total_average.flops * 0.000001\n",
    "\n",
    "    log(f'--- PyTorch Profile: {model_name} ---\\n')\n",
    "\n",
    "\n",
    "    log(\n",
    "        f'CPU time top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_time_total\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'CPU memory usage top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_memory_usage\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'MFLOPs top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"flops\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'Total averages\\n'\n",
    "        f'CPU time total [ms]: {cpu_time_ms}\\n' \n",
    "        f'Self CPU time total [ms]: {self_cpu_time_ms}\\n'\n",
    "        f'CPU memory usage [Mb]: {cpu_memory_usage_mb}\\n'\n",
    "        f'Self CPU memory usage [Mb]: {self_cpu_memory_usage_mb}\\n'\n",
    "        f'MFLOPs: {m_flops}\\n'\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([cpu_memory_usage_mb, mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))\n",
    "    samples_per_cpu_second = num_samples / (self_cpu_time_ms * 0.001)\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': self_cpu_time_ms,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': m_flops,\n",
    "        'samples_per_cpu_second': samples_per_cpu_second,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per CPU second: {samples_per_cpu_second}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model_micro_controller(model_results: ModelResults, micro_controller: MicroController, options: BenchmarkOptions) -> ModelMicroControllerResults:\n",
    "    controller_cpu_speed_ghz = micro_controller['cpu_speed_ghz']\n",
    "    benchmark_cpu_speed_ghz = options['cpu_speed_ghz']\n",
    "    cpu_time_factor = benchmark_cpu_speed_ghz / controller_cpu_speed_ghz\n",
    "\n",
    "    estimated_cpu_time_total_ms = model_results['cpu_time_total_ms'] * cpu_time_factor\n",
    "    estimated_inference_time_ms = model_results['mean_inference_time_ms'] * cpu_time_factor\n",
    "\n",
    "    estimated_samples_per_cpu_second = model_results['samples_per_cpu_second'] / cpu_time_factor\n",
    "    estimated_samples_per_inference_second = model_results['samples_per_inference_second'] / cpu_time_factor\n",
    "\n",
    "    memory_usage_percentage = (model_results['mean_memory_usage_mb'] / micro_controller['memory_mb']) * 100\n",
    "\n",
    "    target_sampling_rate_hz = options['target_sampling_rate_khz'] * 1000\n",
    "\n",
    "    compatible = (\n",
    "        estimated_samples_per_cpu_second >= target_sampling_rate_hz \n",
    "        and estimated_samples_per_inference_second >= target_sampling_rate_hz\n",
    "        and memory_usage_percentage <= 100\n",
    "    )\n",
    "\n",
    "    results: ModelMicroControllerResults = {\n",
    "        'model_name': model_results['name'],\n",
    "        'estimated_cpu_time_total_ms': estimated_cpu_time_total_ms,\n",
    "        'estimated_inference_time_ms': estimated_inference_time_ms,\n",
    "        'estimated_samples_per_cpu_second': estimated_samples_per_cpu_second,\n",
    "        'estimated_samples_per_inference_second': estimated_samples_per_inference_second,\n",
    "        'memory_usage_percentage': memory_usage_percentage,\n",
    "        'compatible': compatible,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(models: list[Model], micro_controllers: list[MicroController], options: BenchmarkOptions):\n",
    "    ##################\n",
    "    # Create logfile #\n",
    "    ##################\n",
    "\n",
    "    logfile_path = options['logfile_path']\n",
    "    f = open(logfile_path, 'w')\n",
    "    f.close()\n",
    "\n",
    "    log = create_logger(logfile_path)\n",
    "\n",
    "    ###############################\n",
    "    # Benchmark individual models #\n",
    "    ###############################\n",
    "\n",
    "    log(\n",
    "        f'--- Benchmarking {len(models)} models ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "    models_results = [benchmark_model(model, options, log) for model in models]\n",
    "\n",
    "    ##########################################\n",
    "    # Benchmark models for micro controllers #\n",
    "    ##########################################\n",
    "\n",
    "    log(\n",
    "        f'\\n--- Benchmarking {len(models)} models for {len(micro_controllers)} micro controllers ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    for micro_controller in micro_controllers:\n",
    "        log_hash_comment(micro_controller['name'], log)\n",
    "        log(\n",
    "            'Info\\n'\n",
    "            f'Architecture: {micro_controller[\"architecture\"]}\\n'\n",
    "            f'Memory [Mb]: {micro_controller[\"memory_mb\"]}\\n'\n",
    "            f'CPU speed [GHz]: {micro_controller[\"cpu_speed_ghz\"]}\\n'\n",
    "        )\n",
    "        table = PrettyTable(\n",
    "            ['Model', 'Estimated CPU time [ms]', 'Estimated inference time [ms]', 'Estimated samples per CPU second', 'Estimated samples per inference second', 'Memory usage %', 'COMPATIBLE']\n",
    "        )\n",
    "        results = [benchmark_model_micro_controller(model_result, micro_controller, options).values() for model_result in models_results]\n",
    "        table.add_rows(results)\n",
    "        log(table.get_string())\n",
    "        log('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret PyTorch Profiler results\n",
    "\n",
    "References:\n",
    "- [Recipe](https://h-huang.github.io/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "\n",
    "#### CPU time\n",
    "\n",
    "CPU time vs self CPU time: operators can call other operators -> self cpu time excludes time spent in children operator calls, while total cpu time includes it\n",
    "\n",
    "#### Memory usage\n",
    "\n",
    "- Shows amount of memory used by the model’s tensors:\n",
    "- That was allocated (or released) during the execution of the model’s operators\n",
    "\n",
    "Self memory: corresponds to the memory allocated (released) by the operator, excluding the children calls to the other operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch SILERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Moritz/.cache\\torch\\hub\\snakers4_silero-models_master\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Input statistics ---\n",
      "Sampling rate: 48000 Hz\n",
      "Number of samples: 518400\n",
      "\n",
      "the boch canoe slit on the smooth planks blew the sheet to the dark blue background it's easy to tell a depth of a well four hours of steady work faced us\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create SILERO model #\n",
    "#######################\n",
    "\n",
    "# Always use CPU (simulate run on micro controller)\n",
    "device = torch.device('cpu')  \n",
    "\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device)\n",
    "(read_batch, split_into_batches,\n",
    " read_audio, prepare_model_input) = utils  # see function signature for details\n",
    "\n",
    "# Download a single file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n",
    "                               dst ='speech_orig.wav', progress=True)\n",
    "test_files = glob('speech_orig.wav')\n",
    "batches = split_into_batches(test_files, batch_size=10)\n",
    "input = prepare_model_input(read_batch(batches[0]),\n",
    "                            device=device)\n",
    "\n",
    "######################################\n",
    "# Get number of samples in test data #\n",
    "######################################\n",
    "\n",
    "audio_file = wave.open(test_files[0], 'r')\n",
    "sampling_rate = audio_file.getframerate()\n",
    "num_samples = audio_file.getnframes()\n",
    "\n",
    "print(\n",
    "    f'\\n--- Input statistics ---\\n'\n",
    "    f'Sampling rate: {sampling_rate} Hz\\n'\n",
    "    f'Number of samples: {num_samples}\\n'\n",
    ")\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "output = model(input)\n",
    "for example in output:\n",
    "    print(decoder(example.cpu()))\n",
    "\n",
    "#################################\n",
    "# Create model for benchmarking #\n",
    "#################################\n",
    "\n",
    "def infer():\n",
    "    _out = model(input)\n",
    "\n",
    "silero_model: Model = {\n",
    "    'name': 'SILERO',\n",
    "    'num_inferred_samples': num_samples,\n",
    "    'infer': infer,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro Controllers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "esp32: MicroController = {\n",
    "    'name': 'ESP32',\n",
    "    'architecture': '32-bit RISC-V',\n",
    "    'cpu_speed_ghz': 0.24,\n",
    "    'memory_mb': 0.23,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_zero: MicroController = {\n",
    "    'name': 'Raspberry Pi Zero v1.3',\n",
    "    'architecture': '32-bit ARM',\n",
    "    'cpu_speed_ghz': 1,\n",
    "    'memory_mb': 512,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_3_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 3 B v1.2',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.2,\n",
    "    'memory_mb': 1000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Benchmarking 1 models ---\n",
      "\n",
      "\n",
      "##########\n",
      "# SILERO #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: SILERO ---\n",
      "\n",
      "CPU time top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "               model_inference        61.81%     490.163ms       100.00%     793.057ms     793.057ms           0 b    -530.72 Kb             1            --  \n",
      "                       forward         2.73%      21.646ms        38.19%     302.894ms     302.894ms     530.72 Kb     -58.61 Mb             1            --  \n",
      "                  aten::linear         0.67%       5.285ms        13.89%     110.169ms       1.721ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "                   aten::addmm        12.20%      96.791ms        12.84%     101.842ms       1.591ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::conv1d         0.27%       2.132ms        11.05%      87.625ms       3.651ms      10.82 Mb     -10.31 Mb            24            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 793.057ms\n",
      "\n",
      "CPU memory usage top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::empty         0.12%     971.000us         0.12%     971.000us       3.963us      74.73 Mb      74.73 Mb           245            --  \n",
      "              aten::empty_like         0.17%       1.336ms         0.21%       1.646ms      16.626us      40.00 Mb     542.00 Kb            99            --  \n",
      "                   aten::clone         0.36%       2.818ms         1.25%       9.925ms     101.276us      38.81 Mb      -1.06 Mb            98            --  \n",
      "                   aten::addmm        12.20%      96.791ms        12.84%     101.842ms       1.591ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::linear         0.67%       5.285ms        13.89%     110.169ms       1.721ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 793.057ms\n",
      "\n",
      "MFLOPs top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::addmm        12.20%      96.791ms        12.84%     101.842ms       1.591ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                     aten::bmm         2.15%      17.073ms         2.15%      17.073ms     533.531us      11.97 Mb      11.97 Mb            32      1506.296  \n",
      "                     aten::add         0.72%       5.723ms         0.72%       5.723ms      78.397us     -14.33 Mb     -14.33 Mb            73         9.058  \n",
      "                     aten::mul         0.43%       3.400ms         0.44%       3.516ms      51.706us      14.04 Mb      14.04 Mb            68         7.188  \n",
      "               model_inference        61.81%     490.163ms       100.00%     793.057ms     793.057ms           0 b    -530.72 Kb             1            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 793.057ms\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 1811.618\n",
      "Self CPU time total [ms]: 793.057\n",
      "CPU memory usage [Mb]: 355.9463424682617\n",
      "Self CPU memory usage [Mb]: 0.0\n",
      "MFLOPs: 11765.032691999999\n",
      "\n",
      "--- Psutil memory_full_info: SILERO ---\n",
      "\n",
      "Over 10 iterations\n",
      "Mean RSS [Mb]: 438.291015625\n",
      "Std RSS: 1.494140625\n",
      "Mean USS [Mb]: 391.493359375\n",
      "Std USS: 1.344140625\n",
      "\n",
      "--- Timeit default_timer: SILERO ---\n",
      "\n",
      "Over 10 iterations\n",
      "Mean inference time [ms]: 196.77227998618037\n",
      "Std inference time: 7.750830627149103\n",
      "\n",
      "--- Overall results: SILERO ---\n",
      "\n",
      "Mean memory usage [Mb]: 276.5949048189616\n",
      "Samples per CPU second: 653673.0651138569\n",
      "Samples per inference second: 2634517.423065932\n",
      "\n",
      "\n",
      "--- Benchmarking 1 models for 3 micro controllers ---\n",
      "\n",
      "\n",
      "#########\n",
      "# ESP32 #\n",
      "#########\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit RISC-V\n",
      "Memory [Mb]: 0.23\n",
      "CPU speed [GHz]: 0.24\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    12226.295416666668   |       3033.5726497869477      |        42400.41503441234         |           170887.61663130368           | 120258.65426911373 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "##########################\n",
      "# Raspberry Pi Zero v1.3 #\n",
      "##########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit ARM\n",
      "Memory [Mb]: 512\n",
      "CPU speed [GHz]: 1\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    2934.3109000000004   |       728.0574359488674       |        176668.39597671808        |           712031.7359637654            | 54.022442347453435 |    True    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "#########################\n",
      "# Raspberry Pi 3 B v1.2 #\n",
      "#########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 1000\n",
      "CPU speed [GHz]: 1.2\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %  | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| SILERO |    2445.2590833333334   |       606.7145299573895       |        212002.07517206168        |           854438.0831565184            | 27.65949048189616 |    True    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# Register models and micro controllers #\n",
    "#########################################\n",
    "\n",
    "models: list[Model] = [silero_model]\n",
    "\n",
    "micro_controllers: list[MicroController] = [esp32, pi_zero, pi_3_b]\n",
    "\n",
    "#########################\n",
    "# Set benchmark options #\n",
    "#########################\n",
    "\n",
    "benchmark_options: BenchmarkOptions = {\n",
    "    'cpu_speed_ghz': 3.7,\n",
    "    'target_sampling_rate_khz': 16,\n",
    "    'logfile_path': 'benchmark.txt'\n",
    "}\n",
    "\n",
    "#################\n",
    "# Run benchmark #\n",
    "#################\n",
    "\n",
    "benchmark(models, micro_controllers, benchmark_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
