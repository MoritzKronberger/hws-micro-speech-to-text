{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Micro Controller Benchmark\n",
    "\n",
    "Benchmark PyTorch Models and generate Compatibility list for micro controllers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "# %pip install torch torchaudio omegaconf soundfile numpy prettytable transformers pocketsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\hws\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import wave\n",
    "import platform\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from timeit import default_timer\n",
    "from typing import TypedDict, Callable\n",
    "from prettytable import PrettyTable\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from transformers import AutoProcessor, HubertForCTC\n",
    "from pocketsphinx import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "\n",
    "class Model(TypedDict):\n",
    "    name: str\n",
    "    num_inferred_samples: int\n",
    "    infer: Callable[[None], list[str]]\n",
    "    is_pytorch: bool\n",
    "\n",
    "class MicroController(TypedDict):\n",
    "    name: str\n",
    "    architecture: str\n",
    "    memory_mb: float\n",
    "    cpu_speed_ghz: float\n",
    "\n",
    "class ModelResults:\n",
    "    name: str\n",
    "    cpu_time_total_ms: float | None\n",
    "    mean_inference_time_ms: float\n",
    "    mean_memory_usage_mb: float\n",
    "    m_flops: float | None\n",
    "    samples_per_cpu_second: float | None\n",
    "    samples_per_inference_second: float\n",
    "\n",
    "class ModelMicroControllerResults:\n",
    "    model_name: str\n",
    "    estimated_cpu_time_total_ms: float | None\n",
    "    estimated_inference_time_ms: float\n",
    "    estimated_samples_per_cpu_second: float | None\n",
    "    estimated_samples_per_inference_second: float\n",
    "    memory_usage_percentage: float\n",
    "    compatible: bool\n",
    "\n",
    "class BenchmarkOptions:\n",
    "    cpu_speed_ghz: float\n",
    "    target_sampling_rate_khz: float\n",
    "    logfile_path: str\n",
    "\n",
    "Log = Callable[[str], None]\n",
    "\n",
    "CreateModel = Callable[[None], Model]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_mb(byte: int) -> int:\n",
    "    return byte / (1024 ** 2)\n",
    "\n",
    "def create_logger(logifle_path: str) -> Log:\n",
    "    def __log(msg: str):\n",
    "        with open(logifle_path, 'a') as f:\n",
    "            f.write(f'{msg}\\n' )\n",
    "        print(msg)\n",
    "    return __log\n",
    "\n",
    "def log_hash_comment(content: str, log: Log):\n",
    "    content_str = f'# {content} #'\n",
    "    num_hashes = len(content_str)\n",
    "    hashes = '#' * num_hashes\n",
    "    log(\n",
    "        f'{hashes}\\n'\n",
    "        f'{content_str}\\n'\n",
    "        f'{hashes}\\n'\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_pytorch_model(model: Model, log: Log, row_limit = 5, iterations = 5) -> ModelResults:\n",
    "\n",
    "    #####################\n",
    "    # Instantiate Model #\n",
    "    #####################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ########################\n",
    "    # Run PyTorch Profiler #\n",
    "    ########################\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], profile_memory=True, with_flops=True, record_shapes=True, with_stack=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            _out = model['infer']()\n",
    "\n",
    "    key_averages = prof.key_averages()\n",
    "    total_average = key_averages.total_average()\n",
    "\n",
    "    key_averages.table()\n",
    "\n",
    "    cpu_time_ms = total_average.cpu_time_total * 0.001\n",
    "    self_cpu_time_ms = total_average.self_cpu_time_total * 0.001\n",
    "    cpu_memory_usage_mb = byte_to_mb(total_average.cpu_memory_usage)\n",
    "    self_cpu_memory_usage_mb = byte_to_mb(total_average.self_cpu_memory_usage)\n",
    "    m_flops = total_average.flops * 0.000001\n",
    "\n",
    "    log(f'--- PyTorch Profile: {model_name} ---\\n')\n",
    "\n",
    "\n",
    "    log(\n",
    "        f'CPU time top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_time_total\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'CPU memory usage top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_memory_usage\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'MFLOPs top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"flops\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'Total averages\\n'\n",
    "        f'CPU time total [ms]: {cpu_time_ms}\\n' \n",
    "        f'Self CPU time total [ms]: {self_cpu_time_ms}\\n'\n",
    "        f'CPU memory usage [Mb]: {cpu_memory_usage_mb}\\n'\n",
    "        f'Self CPU memory usage [Mb]: {self_cpu_memory_usage_mb}\\n'\n",
    "        f'MFLOPs: {m_flops}\\n'\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))  # cpu_memory_usage_mb\n",
    "    samples_per_cpu_second = num_samples / (self_cpu_time_ms * 0.001)\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': self_cpu_time_ms,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': m_flops,\n",
    "        'samples_per_cpu_second': samples_per_cpu_second,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per CPU second: {samples_per_cpu_second}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_unknown_model(model: Model, log: Log, iterations = 5) -> ModelResults:\n",
    "\n",
    "    #####################\n",
    "    # Instantiate Model #\n",
    "    #####################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': None,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': None,\n",
    "        'samples_per_cpu_second': None,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(create_model: CreateModel, log: Log) -> ModelResults:\n",
    "    # Instantiate model\n",
    "    model = create_model()\n",
    "    is_pythorch_model = model['is_pytorch']\n",
    "    # Benchmark based on model type\n",
    "    if is_pythorch_model:\n",
    "        results = benchmark_pytorch_model(model, log)\n",
    "    else:\n",
    "        results = benchmark_unknown_model(model, log)\n",
    "    # Delete model from memory before running next benchmark\n",
    "    del model\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model_micro_controller(model_results: ModelResults, micro_controller: MicroController, options: BenchmarkOptions) -> ModelMicroControllerResults:\n",
    "    controller_cpu_speed_ghz = micro_controller['cpu_speed_ghz']\n",
    "    benchmark_cpu_speed_ghz = options['cpu_speed_ghz']\n",
    "    cpu_time_factor = benchmark_cpu_speed_ghz / controller_cpu_speed_ghz\n",
    "\n",
    "    if model_results['cpu_time_total_ms'] is not None:\n",
    "        estimated_cpu_time_total_ms = model_results['cpu_time_total_ms'] * cpu_time_factor\n",
    "    else:\n",
    "        estimated_cpu_time_total_ms = None\n",
    "    estimated_inference_time_ms = model_results['mean_inference_time_ms'] * cpu_time_factor\n",
    "\n",
    "    if model_results['samples_per_cpu_second'] is not None:\n",
    "        estimated_samples_per_cpu_second = model_results['samples_per_cpu_second'] / cpu_time_factor\n",
    "    else:\n",
    "        estimated_samples_per_cpu_second = None\n",
    "    estimated_samples_per_inference_second = model_results['samples_per_inference_second'] / cpu_time_factor\n",
    "\n",
    "    memory_usage_percentage = (model_results['mean_memory_usage_mb'] / micro_controller['memory_mb']) * 100\n",
    "\n",
    "    target_sampling_rate_hz = options['target_sampling_rate_khz'] * 1000\n",
    "\n",
    "    compatible = (\n",
    "        # estimated_samples_per_cpu_second >= target_sampling_rate_hz \n",
    "        estimated_samples_per_inference_second >= target_sampling_rate_hz\n",
    "        and memory_usage_percentage <= 100\n",
    "    )\n",
    "\n",
    "    results: ModelMicroControllerResults = {\n",
    "        'model_name': model_results['name'],\n",
    "        'estimated_cpu_time_total_ms': estimated_cpu_time_total_ms,\n",
    "        'estimated_inference_time_ms': estimated_inference_time_ms,\n",
    "        'estimated_samples_per_cpu_second': estimated_samples_per_cpu_second,\n",
    "        'estimated_samples_per_inference_second': estimated_samples_per_inference_second,\n",
    "        'memory_usage_percentage': memory_usage_percentage,\n",
    "        'compatible': compatible,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(create_models: list[CreateModel], micro_controllers: list[MicroController], options: BenchmarkOptions):\n",
    "    ##################\n",
    "    # Create logfile #\n",
    "    ##################\n",
    "\n",
    "    logfile_path = options['logfile_path']\n",
    "    f = open(logfile_path, 'w')\n",
    "    f.close()\n",
    "\n",
    "    log = create_logger(logfile_path)\n",
    "\n",
    "    ###################\n",
    "    # Log system info #\n",
    "    ###################\n",
    "\n",
    "    machine = platform.machine()\n",
    "    system = platform.system()\n",
    "    version = platform.version()\n",
    "    processor = platform.processor()\n",
    "    ram = psutil.virtual_memory().total / (1024.0 **3)\n",
    "\n",
    "    log(\n",
    "        f'--- Running benchmark on ---\\n'\n",
    "        '\\n'\n",
    "        f'Arch: {machine}\\n'\n",
    "        f'Platform: {system} {version}\\n'\n",
    "        f'CPU: {processor}, {options[\"cpu_speed_ghz\"]} GHz\\n'\n",
    "        f'RAM: {ram} GB\\n'\n",
    "    )\n",
    "\n",
    "\n",
    "    ###############################\n",
    "    # Benchmark individual models #\n",
    "    ###############################\n",
    "\n",
    "    log(\n",
    "        f'--- Benchmarking {len(create_models)} models ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "    models_results = [benchmark_model(create_model, log) for create_model in create_models]\n",
    "\n",
    "    ##########################################\n",
    "    # Benchmark models for micro controllers #\n",
    "    ##########################################\n",
    "\n",
    "    log(\n",
    "        f'\\n--- Benchmarking {len(create_models)} models for {len(micro_controllers)} micro controllers ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    for micro_controller in micro_controllers:\n",
    "        log_hash_comment(micro_controller['name'], log)\n",
    "        log(\n",
    "            'Info\\n'\n",
    "            f'Architecture: {micro_controller[\"architecture\"]}\\n'\n",
    "            f'Memory [Mb]: {micro_controller[\"memory_mb\"]}\\n'\n",
    "            f'CPU speed [GHz]: {micro_controller[\"cpu_speed_ghz\"]}\\n'\n",
    "        )\n",
    "        table = PrettyTable(\n",
    "            ['Model', 'Estimated CPU time [ms]', 'Estimated inference time [ms]', 'Estimated samples per CPU second', 'Estimated samples per inference second', 'Memory usage %', 'COMPATIBLE']\n",
    "        )\n",
    "        results = [benchmark_model_micro_controller(model_result, micro_controller, options).values() for model_result in models_results]\n",
    "        table.add_rows(results)\n",
    "        log(table.get_string())\n",
    "        log('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret PyTorch Profiler results\n",
    "\n",
    "References:\n",
    "- [Recipe](https://h-huang.github.io/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "\n",
    "#### CPU time\n",
    "\n",
    "CPU time vs self CPU time: operators can call other operators -> self cpu time excludes time spent in children operator calls, while total cpu time includes it\n",
    "\n",
    "#### Memory usage\n",
    "\n",
    "- Shows amount of memory used by the model’s tensors:\n",
    "- That was allocated (or released) during the execution of the model’s operators\n",
    "\n",
    "Self memory: corresponds to the memory allocated (released) by the operator, excluding the children calls to the other operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Silero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Moritz/.cache\\torch\\hub\\snakers4_silero-models_master\n",
      "100%|██████████| 0.99M/0.99M [00:00<00:00, 1.16MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Input statistics ---\n",
      "Sampling rate: 48000 Hz\n",
      "Number of samples: 518400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Use Silero utils to download model and test file #\n",
    "####################################################\n",
    "\n",
    "# Always use CPU (simulate run on micro controller)\n",
    "device = torch.device('cpu')  \n",
    "\n",
    "# Download model, decoder and utils\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device\n",
    ")\n",
    "(read_batch, split_into_batches, _ , prepare_model_input) = utils  # see function signature for details\n",
    "\n",
    "# Download a single test file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n",
    "                            dst ='speech_orig.wav', progress=True)\n",
    "test_files = glob('speech_orig.wav')\n",
    "\n",
    "######################################\n",
    "# Get number of samples in test data #\n",
    "######################################\n",
    "\n",
    "audio_file = wave.open(test_files[0], 'r')\n",
    "sampling_rate = audio_file.getframerate()\n",
    "num_samples = audio_file.getnframes()\n",
    "\n",
    "print(\n",
    "    f'\\n--- Input statistics ---\\n'\n",
    "    f'Sampling rate: {sampling_rate} Hz\\n'\n",
    "    f'Number of samples: {num_samples}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the boch canoe slit on the smooth planks blew the sheet to the dark blue background it's easy to tell a depth of a well four hours of steady work faced us\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create SILERO model #\n",
    "#######################\n",
    "\n",
    "def create_silero_model():\n",
    "    # Prepare input data\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_silero():\n",
    "        input = prepare_model_input(read_batch(batches[0]), device=device)\n",
    "        output = model(input)\n",
    "        return [decoder(example.cpu()) for example in output]\n",
    "\n",
    "    silero_model: Model = {\n",
    "        'name': 'Silero',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_silero,\n",
    "        'is_pytorch': True,\n",
    "    }\n",
    "\n",
    "    return silero_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "silero_model = create_silero_model()\n",
    "transcription = silero_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del silero_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PocketSphinx\n",
    "\n",
    "Reference: [PyPI](https://pypi.org/project/pocketsphinx/), [Example](https://github.com/cmusphinx/pocketsphinx/blob/master/examples/simple.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pitch kinnear slipped on the snooze planks linda say to the doc the loop act grounds it's easy to tell him that the well for allies and steady work face death\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Create PocketSphinx model #\n",
    "#############################\n",
    "\n",
    "def create_pocket_sphinx_model():\n",
    "\n",
    "    # Configure decoder\n",
    "    decoder = Decoder(samprate=sampling_rate)\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_pocket_sphinx():\n",
    "        with wave.open('speech_orig.wav', 'rb') as audio:\n",
    "            decoder.start_utt()\n",
    "            decoder.process_raw(audio.getfp().read(), full_utt=True)\n",
    "            decoder.end_utt()\n",
    "            return decoder.hyp().hypstr\n",
    "       \n",
    "\n",
    "    pocket_sphinx_model: Model = {\n",
    "        'name': 'PocketSphinx',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_pocket_sphinx,\n",
    "        'is_pytorch': False,\n",
    "    }\n",
    "\n",
    "    return pocket_sphinx_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "pocket_sphinx_model = create_pocket_sphinx_model()\n",
    "transcription = pocket_sphinx_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del pocket_sphinx_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuBERT\n",
    "\n",
    "Reference: [Hugging Face](https://huggingface.co/docs/transformers/model_doc/hubert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"THE BIRCH CANOE SLID ON THE SMOOTH PLANKS GLUE THE SHEET TO THE DARK BLUE BACKGROUND IT'S EASY TO TELL THE DEPTH OF A WELL FOUR HOURS OF STEADY WORK FACED US\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create HuBERT model #\n",
    "#######################\n",
    "\n",
    "def create_hubert_model():\n",
    "    # Download model\n",
    "    model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "    # Prepare inputs\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_hubert():\n",
    "        inputs = processor(read_batch(batches[0])[0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        return processor.batch_decode(predicted_ids)\n",
    "\n",
    "    hubert_model: Model = {\n",
    "        'name': 'HuBERT',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_hubert,\n",
    "        'is_pytorch': True,\n",
    "    }\n",
    "\n",
    "    return hubert_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "pocket_sphinx_model = create_hubert_model()\n",
    "transcription = pocket_sphinx_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del pocket_sphinx_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro Controllers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "esp32: MicroController = {\n",
    "    'name': 'ESP32',\n",
    "    'architecture': '32-bit RISC-V',\n",
    "    'cpu_speed_ghz': 0.24,\n",
    "    'memory_mb': 0.23,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_zero: MicroController = {\n",
    "    'name': 'Raspberry Pi Zero v1.3',\n",
    "    'architecture': '32-bit ARM',\n",
    "    'cpu_speed_ghz': 1,\n",
    "    'memory_mb': 512,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_3_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 3 B v1.2',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.2,\n",
    "    'memory_mb': 1000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 4 Model B 4Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_4_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 4 Model B 4Go',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.5,\n",
    "    'memory_mb': 4000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running benchmark on ---\n",
      "\n",
      "Arch: AMD64\n",
      "Platform: Windows 10.0.22621\n",
      "CPU: AMD64 Family 23 Model 8 Stepping 2, AuthenticAMD, 3.7 GHz\n",
      "RAM: 15.951824188232422 GB\n",
      "\n",
      "--- Benchmarking 3 models ---\n",
      "\n",
      "\n",
      "################\n",
      "# PocketSphinx #\n",
      "################\n",
      "\n",
      "\n",
      "--- Psutil memory_full_info: PocketSphinx ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 529.0140625\n",
      "Std RSS: 5.85412087346784\n",
      "Mean USS [Mb]: 476.2796875\n",
      "Std USS: 4.924976453385971\n",
      "\n",
      "--- Timeit default_timer: PocketSphinx ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 2059.087139973417\n",
      "Std inference time: 58.26335027243569\n",
      "\n",
      "--- Overall results: PocketSphinx ---\n",
      "\n",
      "Mean memory usage [Mb]: 502.646875\n",
      "Samples per inference second: 251762.05024848663\n",
      "\n",
      "\n",
      "##########\n",
      "# Silero #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: Silero ---\n",
      "\n",
      "CPU time top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "               model_inference        64.85%     501.110ms       100.00%     772.676ms     772.676ms           0 b      -3.82 Mb             1            --  \n",
      "                       forward         2.78%      21.446ms        33.80%     261.153ms     261.153ms     530.72 Kb     -54.00 Mb             1            --  \n",
      "                  aten::linear         0.68%       5.263ms        14.30%     110.512ms       1.727ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "                   aten::addmm        12.56%      97.041ms        13.23%     102.254ms       1.598ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::conv1d         0.21%       1.630ms         7.02%      54.232ms       2.169ms      11.22 Mb     -10.57 Mb            25            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 772.676ms\n",
      "\n",
      "CPU memory usage top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::empty         0.12%     962.000us         0.12%     962.000us       3.802us      77.86 Mb      77.86 Mb           253            --  \n",
      "              aten::empty_like         0.17%       1.297ms         0.22%       1.692ms      17.091us      40.00 Mb     272.00 Kb            99            --  \n",
      "                   aten::clone         0.36%       2.805ms         1.34%      10.372ms     105.837us      39.34 Mb    -272.00 Kb            98            --  \n",
      "                   aten::addmm        12.56%      97.041ms        13.23%     102.254ms       1.598ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::linear         0.68%       5.263ms        14.30%     110.512ms       1.727ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 772.676ms\n",
      "\n",
      "MFLOPs top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::addmm        12.56%      97.041ms        13.23%     102.254ms       1.598ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                     aten::bmm         2.31%      17.822ms         2.31%      17.822ms     556.938us      11.97 Mb      11.97 Mb            32      1506.296  \n",
      "                     aten::add         0.62%       4.794ms         0.62%       4.807ms      64.959us     -15.92 Mb     -15.92 Mb            74         9.058  \n",
      "                     aten::mul         0.43%       3.297ms         0.44%       3.414ms      48.771us      14.04 Mb      14.04 Mb            70         7.188  \n",
      "               model_inference        64.85%     501.110ms       100.00%     772.676ms     772.676ms           0 b      -3.82 Mb             1            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 772.676ms\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 1622.1680000000001\n",
      "Self CPU time total [ms]: 772.676\n",
      "CPU memory usage [Mb]: 362.25722885131836\n",
      "Self CPU memory usage [Mb]: 0.0\n",
      "MFLOPs: 11765.032775\n",
      "\n",
      "--- Psutil memory_full_info: Silero ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 477.64609375\n",
      "Std RSS: 2.1182777981365253\n",
      "Mean USS [Mb]: 426.97109375\n",
      "Std USS: 1.9284924816947369\n",
      "\n",
      "--- Timeit default_timer: Silero ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 203.37620000354946\n",
      "Std inference time: 4.442908417645703\n",
      "\n",
      "--- Overall results: Silero ---\n",
      "\n",
      "Mean memory usage [Mb]: 452.30859375\n",
      "Samples per CPU second: 670915.1054258188\n",
      "Samples per inference second: 2548970.823483537\n",
      "\n",
      "\n",
      "##########\n",
      "# HuBERT #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: HuBERT ---\n",
      "\n",
      "CPU time top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference         6.62%     277.251ms       100.00%        4.188s        4.188s      32.00 Mb      -2.80 Gb             1            --  \n",
      "                    aten::linear         0.14%       5.775ms        60.35%        2.527s      17.311ms     456.95 Mb           0 b           146            --  \n",
      "                     aten::addmm        58.91%        2.467s        60.09%        2.516s      17.235ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                    aten::conv1d         0.00%      85.000us        12.65%     529.827ms      58.870ms     136.70 Mb           0 b             9            --  \n",
      "               aten::convolution         0.00%     131.000us        12.65%     529.742ms      58.860ms     136.70 Mb           0 b             9            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.188s\n",
      "\n",
      "CPU memory usage top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::empty         0.11%       4.443ms         0.11%       4.443ms      14.379us     881.11 Mb     881.11 Mb           309            --  \n",
      "                       aten::add         1.60%      66.964ms         1.60%      66.973ms     826.827us     528.74 Mb     528.74 Mb            81       138.605  \n",
      "                aten::empty_like         0.01%     485.000us         0.08%       3.302ms      29.221us     503.05 Mb           0 b           113            --  \n",
      "                       aten::bmm         6.41%     268.441ms         6.41%     268.449ms       5.593ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                     aten::clone         0.02%     976.000us         3.76%     157.392ms       1.431ms     471.04 Mb           0 b           110            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.188s\n",
      "\n",
      "MFLOPs top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::addmm        58.91%        2.467s        60.09%        2.516s      17.235ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                       aten::bmm         6.41%     268.441ms         6.41%     268.449ms       5.593ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                       aten::add         1.60%      66.964ms         1.60%      66.973ms     826.827us     528.74 Mb     528.74 Mb            81       138.605  \n",
      "                       aten::mul         0.19%       8.052ms         0.21%       8.620ms     319.259us      50.53 Mb      50.53 Mb            27        13.247  \n",
      "                 model_inference         6.62%     277.251ms       100.00%        4.188s        4.188s      32.00 Mb      -2.80 Gb             1            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.188s\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 12959.12\n",
      "Self CPU time total [ms]: 4187.694\n",
      "CPU memory usage [Mb]: 6621.587774276733\n",
      "Self CPU memory usage [Mb]: 32.0\n",
      "MFLOPs: 354856.83403699996\n",
      "\n",
      "--- Psutil memory_full_info: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 1714.86875\n",
      "Std RSS: 2.0535607652091157\n",
      "Mean USS [Mb]: 1667.15078125\n",
      "Std USS: 1.8528733492706673\n",
      "\n",
      "--- Timeit default_timer: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 4313.187359983567\n",
      "Std inference time: 122.17538872933682\n",
      "\n",
      "--- Overall results: HuBERT ---\n",
      "\n",
      "Mean memory usage [Mb]: 1691.009765625\n",
      "Samples per CPU second: 123791.27987861577\n",
      "Samples per inference second: 120189.5389033077\n",
      "\n",
      "\n",
      "\n",
      "--- Benchmarking 3 models for 4 micro controllers ---\n",
      "\n",
      "\n",
      "#########\n",
      "# ESP32 #\n",
      "#########\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit RISC-V\n",
      "Memory [Mb]: 0.23\n",
      "CPU speed [GHz]: 0.24\n",
      "\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "|    Model     | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| PocketSphinx |           None          |       31744.26007459018       |               None               |           16330.511367469402           | 218542.1195652174  |   False    |\n",
      "|    Silero    |    11912.088333333335   |       3135.3830833880543      |         43518.8176492423         |           165338.64800974293           | 196655.91032608695 |   False    |\n",
      "|    HuBERT    |    64560.28250000001    |       66494.97179974667       |        8029.704640775076         |           7796.078199133472            | 735221.6372282607  |   False    |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "##########################\n",
      "# Raspberry Pi Zero v1.3 #\n",
      "##########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit ARM\n",
      "Memory [Mb]: 512\n",
      "CPU speed [GHz]: 1\n",
      "\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "|    Model     | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %  | COMPATIBLE |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| PocketSphinx |           None          |       7618.622417901643       |               None               |           68043.79736445584            |  98.1732177734375 |    True    |\n",
      "|    Silero    |    2858.9012000000002   |        752.491940013133       |        181328.40687184292        |           688911.0333739289            | 88.34152221679688 |    True    |\n",
      "|    HuBERT    |    15494.467800000002   |       15958.793231939198      |        33457.10266989615         |           32483.65916305613            | 330.2753448486328 |   False    |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "\n",
      "\n",
      "#########################\n",
      "# Raspberry Pi 3 B v1.2 #\n",
      "#########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 1000\n",
      "CPU speed [GHz]: 1.2\n",
      "\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "|    Model     | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %  | COMPATIBLE |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| PocketSphinx |           None          |       6348.852014918036       |               None               |           81652.55683734702            | 50.26468750000001 |    True    |\n",
      "|    Silero    |    2382.4176666666667   |       627.0766166776109       |        217594.0882462115         |           826693.2400487147            |    45.230859375   |    True    |\n",
      "|    HuBERT    |    12912.056500000002   |       13298.994359949333      |        40148.52320387538         |           38980.39099566736            |   169.1009765625  |   False    |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "\n",
      "\n",
      "##############################\n",
      "# Raspberry Pi 4 Model B 4Go #\n",
      "##############################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 4000\n",
      "CPU speed [GHz]: 1.5\n",
      "\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "|    Model     | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| PocketSphinx |           None          |       5079.081611934429       |               None               |           102065.69604668376           | 12.566171875000002 |    True    |\n",
      "|    Silero    |    1905.9341333333336   |       501.6612933420887       |        271992.6103077644         |           1033366.5500608933           |   11.30771484375   |    True    |\n",
      "|    HuBERT    |        10329.6452       |       10639.195487959467      |        50185.654004844226        |           48725.488744584196           |  42.275244140625   |    True    |\n",
      "+--------------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# Register models and micro controllers #\n",
    "#########################################\n",
    "\n",
    "models: list[Model] = [create_pocket_sphinx_model, create_silero_model, create_hubert_model]\n",
    "\n",
    "micro_controllers: list[MicroController] = [esp32, pi_zero, pi_3_b, pi_4_b]\n",
    "\n",
    "#########################\n",
    "# Set benchmark options #\n",
    "#########################\n",
    "\n",
    "benchmark_options: BenchmarkOptions = {\n",
    "    'cpu_speed_ghz': 3.7,\n",
    "    'target_sampling_rate_khz': 16,\n",
    "    'logfile_path': 'benchmark.txt'\n",
    "}\n",
    "\n",
    "#################\n",
    "# Run benchmark #\n",
    "#################\n",
    "\n",
    "benchmark(models, micro_controllers, benchmark_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
