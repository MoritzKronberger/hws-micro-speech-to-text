{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Micro Controller Benchmark\n",
    "\n",
    "Benchmark PyTorch Models and generate Compatibility list for micro controllers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "# %pip install torch torchaudio omegaconf soundfile numpy prettytable transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\hws\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import wave\n",
    "import platform\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from glob import glob\n",
    "from timeit import default_timer\n",
    "from typing import TypedDict, Callable\n",
    "from prettytable import PrettyTable\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from transformers import AutoProcessor, HubertForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "\n",
    "class Model(TypedDict):\n",
    "    name: str\n",
    "    num_inferred_samples: int\n",
    "    infer: Callable[[None], list[str]]\n",
    "\n",
    "class MicroController(TypedDict):\n",
    "    name: str\n",
    "    architecture: str\n",
    "    memory_mb: float\n",
    "    cpu_speed_ghz: float\n",
    "\n",
    "class ModelResults:\n",
    "    name: str\n",
    "    cpu_time_total_ms: float\n",
    "    mean_inference_time_ms: float\n",
    "    mean_memory_usage_mb: float\n",
    "    m_flops: float\n",
    "    samples_per_cpu_second: float\n",
    "    samples_per_inference_second: float\n",
    "\n",
    "class ModelMicroControllerResults:\n",
    "    model_name: str\n",
    "    estimated_cpu_time_total_ms: float\n",
    "    estimated_inference_time_ms: float\n",
    "    estimated_samples_per_cpu_second: float\n",
    "    estimated_samples_per_inference_second: float\n",
    "    memory_usage_percentage: float\n",
    "    compatible: bool\n",
    "\n",
    "class BenchmarkOptions:\n",
    "    cpu_speed_ghz: float\n",
    "    target_sampling_rate_khz: float\n",
    "    logfile_path: str\n",
    "\n",
    "Log = Callable[[str], None]\n",
    "\n",
    "CreateModel = Callable[[None], Model]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_mb(byte: int) -> int:\n",
    "    return byte / (1024 ** 2)\n",
    "\n",
    "def create_logger(logifle_path: str) -> Log:\n",
    "    def __log(msg: str):\n",
    "        with open(logifle_path, 'a') as f:\n",
    "            f.write(f'{msg}\\n' )\n",
    "        print(msg)\n",
    "    return __log\n",
    "\n",
    "def log_hash_comment(content: str, log: Log):\n",
    "    content_str = f'# {content} #'\n",
    "    num_hashes = len(content_str)\n",
    "    hashes = '#' * num_hashes\n",
    "    log(\n",
    "        f'{hashes}\\n'\n",
    "        f'{content_str}\\n'\n",
    "        f'{hashes}\\n'\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(create_model: CreateModel, options: BenchmarkOptions, log: Log, row_limit = 5, iterations = 5) -> ModelResults:\n",
    "\n",
    "    #####################\n",
    "    # Instantiate Model #\n",
    "    #####################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ########################\n",
    "    # Run PyTorch Profiler #\n",
    "    ########################\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], profile_memory=True, with_flops=True, record_shapes=True, with_stack=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            _out = model['infer']()\n",
    "\n",
    "    key_averages = prof.key_averages()\n",
    "    total_average = key_averages.total_average()\n",
    "\n",
    "    key_averages.table()\n",
    "\n",
    "    cpu_time_ms = total_average.cpu_time_total * 0.001\n",
    "    self_cpu_time_ms = total_average.self_cpu_time_total * 0.001\n",
    "    cpu_memory_usage_mb = byte_to_mb(total_average.cpu_memory_usage)\n",
    "    self_cpu_memory_usage_mb = byte_to_mb(total_average.self_cpu_memory_usage)\n",
    "    m_flops = total_average.flops * 0.000001\n",
    "\n",
    "    log(f'--- PyTorch Profile: {model_name} ---\\n')\n",
    "\n",
    "\n",
    "    log(\n",
    "        f'CPU time top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_time_total\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'CPU memory usage top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_memory_usage\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'MFLOPs top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"flops\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'Total averages\\n'\n",
    "        f'CPU time total [ms]: {cpu_time_ms}\\n' \n",
    "        f'Self CPU time total [ms]: {self_cpu_time_ms}\\n'\n",
    "        f'CPU memory usage [Mb]: {cpu_memory_usage_mb}\\n'\n",
    "        f'Self CPU memory usage [Mb]: {self_cpu_memory_usage_mb}\\n'\n",
    "        f'MFLOPs: {m_flops}\\n'\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([cpu_memory_usage_mb, mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))\n",
    "    samples_per_cpu_second = num_samples / (self_cpu_time_ms * 0.001)\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': self_cpu_time_ms,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': m_flops,\n",
    "        'samples_per_cpu_second': samples_per_cpu_second,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per CPU second: {samples_per_cpu_second}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "    )\n",
    "\n",
    "    # Delete model before next benchmark\n",
    "    del model\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model_micro_controller(model_results: ModelResults, micro_controller: MicroController, options: BenchmarkOptions) -> ModelMicroControllerResults:\n",
    "    controller_cpu_speed_ghz = micro_controller['cpu_speed_ghz']\n",
    "    benchmark_cpu_speed_ghz = options['cpu_speed_ghz']\n",
    "    cpu_time_factor = benchmark_cpu_speed_ghz / controller_cpu_speed_ghz\n",
    "\n",
    "    estimated_cpu_time_total_ms = model_results['cpu_time_total_ms'] * cpu_time_factor\n",
    "    estimated_inference_time_ms = model_results['mean_inference_time_ms'] * cpu_time_factor\n",
    "\n",
    "    estimated_samples_per_cpu_second = model_results['samples_per_cpu_second'] / cpu_time_factor\n",
    "    estimated_samples_per_inference_second = model_results['samples_per_inference_second'] / cpu_time_factor\n",
    "\n",
    "    memory_usage_percentage = (model_results['mean_memory_usage_mb'] / micro_controller['memory_mb']) * 100\n",
    "\n",
    "    target_sampling_rate_hz = options['target_sampling_rate_khz'] * 1000\n",
    "\n",
    "    compatible = (\n",
    "        estimated_samples_per_cpu_second >= target_sampling_rate_hz \n",
    "        and estimated_samples_per_inference_second >= target_sampling_rate_hz\n",
    "        and memory_usage_percentage <= 100\n",
    "    )\n",
    "\n",
    "    results: ModelMicroControllerResults = {\n",
    "        'model_name': model_results['name'],\n",
    "        'estimated_cpu_time_total_ms': estimated_cpu_time_total_ms,\n",
    "        'estimated_inference_time_ms': estimated_inference_time_ms,\n",
    "        'estimated_samples_per_cpu_second': estimated_samples_per_cpu_second,\n",
    "        'estimated_samples_per_inference_second': estimated_samples_per_inference_second,\n",
    "        'memory_usage_percentage': memory_usage_percentage,\n",
    "        'compatible': compatible,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(create_models: list[CreateModel], micro_controllers: list[MicroController], options: BenchmarkOptions):\n",
    "    ##################\n",
    "    # Create logfile #\n",
    "    ##################\n",
    "\n",
    "    logfile_path = options['logfile_path']\n",
    "    f = open(logfile_path, 'w')\n",
    "    f.close()\n",
    "\n",
    "    log = create_logger(logfile_path)\n",
    "\n",
    "    ###################\n",
    "    # Log system info #\n",
    "    ###################\n",
    "\n",
    "    machine = platform.machine()\n",
    "    system = platform.system()\n",
    "    version = platform.version()\n",
    "    processor = platform.processor()\n",
    "    ram = psutil.virtual_memory().total / (1024.0 **3)\n",
    "\n",
    "    log(\n",
    "        f'--- Running benchmark on ---\\n'\n",
    "        '\\n'\n",
    "        f'Arch: {machine}\\n'\n",
    "        f'Platform: {system} {version}\\n'\n",
    "        f'CPU: {processor}, {options[\"cpu_speed_ghz\"]} GHz\\n'\n",
    "        f'RAM: {ram} GB\\n'\n",
    "    )\n",
    "\n",
    "\n",
    "    ###############################\n",
    "    # Benchmark individual models #\n",
    "    ###############################\n",
    "\n",
    "    log(\n",
    "        f'--- Benchmarking {len(create_models)} models ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "    models_results = [benchmark_model(create_model, options, log) for create_model in create_models]\n",
    "\n",
    "    ##########################################\n",
    "    # Benchmark models for micro controllers #\n",
    "    ##########################################\n",
    "\n",
    "    log(\n",
    "        f'\\n--- Benchmarking {len(create_models)} models for {len(micro_controllers)} micro controllers ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    for micro_controller in micro_controllers:\n",
    "        log_hash_comment(micro_controller['name'], log)\n",
    "        log(\n",
    "            'Info\\n'\n",
    "            f'Architecture: {micro_controller[\"architecture\"]}\\n'\n",
    "            f'Memory [Mb]: {micro_controller[\"memory_mb\"]}\\n'\n",
    "            f'CPU speed [GHz]: {micro_controller[\"cpu_speed_ghz\"]}\\n'\n",
    "        )\n",
    "        table = PrettyTable(\n",
    "            ['Model', 'Estimated CPU time [ms]', 'Estimated inference time [ms]', 'Estimated samples per CPU second', 'Estimated samples per inference second', 'Memory usage %', 'COMPATIBLE']\n",
    "        )\n",
    "        results = [benchmark_model_micro_controller(model_result, micro_controller, options).values() for model_result in models_results]\n",
    "        table.add_rows(results)\n",
    "        log(table.get_string())\n",
    "        log('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret PyTorch Profiler results\n",
    "\n",
    "References:\n",
    "- [Recipe](https://h-huang.github.io/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "\n",
    "#### CPU time\n",
    "\n",
    "CPU time vs self CPU time: operators can call other operators -> self cpu time excludes time spent in children operator calls, while total cpu time includes it\n",
    "\n",
    "#### Memory usage\n",
    "\n",
    "- Shows amount of memory used by the model’s tensors:\n",
    "- That was allocated (or released) during the execution of the model’s operators\n",
    "\n",
    "Self memory: corresponds to the memory allocated (released) by the operator, excluding the children calls to the other operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch SILERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Moritz/.cache\\torch\\hub\\snakers4_silero-models_master\n",
      "100%|██████████| 0.99M/0.99M [00:01<00:00, 543kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Input statistics ---\n",
      "Sampling rate: 48000 Hz\n",
      "Number of samples: 518400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Use SILERO utils to download model and test file #\n",
    "####################################################\n",
    "\n",
    "# Always use CPU (simulate run on micro controller)\n",
    "device = torch.device('cpu')  \n",
    "\n",
    "# Download model, decoder and utils\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device\n",
    ")\n",
    "(read_batch, split_into_batches, _ , prepare_model_input) = utils  # see function signature for details\n",
    "\n",
    "# Download a single test file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n",
    "                            dst ='speech_orig.wav', progress=True)\n",
    "test_files = glob('speech_orig.wav')\n",
    "\n",
    "######################################\n",
    "# Get number of samples in test data #\n",
    "######################################\n",
    "\n",
    "audio_file = wave.open(test_files[0], 'r')\n",
    "sampling_rate = audio_file.getframerate()\n",
    "num_samples = audio_file.getnframes()\n",
    "\n",
    "print(\n",
    "    f'\\n--- Input statistics ---\\n'\n",
    "    f'Sampling rate: {sampling_rate} Hz\\n'\n",
    "    f'Number of samples: {num_samples}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the boch canoe slit on the smooth planks blew the sheet to the dark blue background it's easy to tell a depth of a well four hours of steady work faced us\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create SILERO model #\n",
    "#######################\n",
    "\n",
    "def create_silero_model():\n",
    "    # Prepare input data\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "    input = prepare_model_input(read_batch(batches[0]),\n",
    "                                device=device)\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_silero():\n",
    "        output = model(input)\n",
    "        return [decoder(example.cpu()) for example in output]\n",
    "\n",
    "    silero_model: Model = {\n",
    "        'name': 'SILERO',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_silero,\n",
    "    }\n",
    "\n",
    "    return silero_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "silero_model = create_silero_model()\n",
    "transcription = silero_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del silero_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuBERT\n",
    "\n",
    "Reference: [Hugging Face](https://huggingface.co/docs/transformers/model_doc/hubert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"THE BIRCH CANOE SLID ON THE SMOOTH PLANKS GLUE THE SHEET TO THE DARK BLUE BACKGROUND IT'S EASY TO TELL THE DEPTH OF A WELL FOUR HOURS OF STEADY WORK FACED US\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create HuBERT model #\n",
    "#######################\n",
    "\n",
    "def create_hubert_model():\n",
    "    # Download model\n",
    "    model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "    # Prepare inputs\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "    inputs = processor(read_batch(batches[0])[0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_hubert():\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        return processor.batch_decode(predicted_ids)\n",
    "\n",
    "    hubert_model: Model = {\n",
    "        'name': 'HuBERT',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_hubert,\n",
    "    }\n",
    "\n",
    "    return hubert_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "hubert_model = create_hubert_model()\n",
    "transcription = hubert_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del hubert_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro Controllers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "esp32: MicroController = {\n",
    "    'name': 'ESP32',\n",
    "    'architecture': '32-bit RISC-V',\n",
    "    'cpu_speed_ghz': 0.24,\n",
    "    'memory_mb': 0.23,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_zero: MicroController = {\n",
    "    'name': 'Raspberry Pi Zero v1.3',\n",
    "    'architecture': '32-bit ARM',\n",
    "    'cpu_speed_ghz': 1,\n",
    "    'memory_mb': 512,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_3_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 3 B v1.2',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.2,\n",
    "    'memory_mb': 1000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 4 Model B 4Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_4_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 4 Model B 4Go',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.5,\n",
    "    'memory_mb': 4000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running benchmark on ---\n",
      "\n",
      "Arch: AMD64\n",
      "Platform: Windows 10.0.22621\n",
      "CPU: AMD64 Family 23 Model 8 Stepping 2, AuthenticAMD, 3.7 GHz\n",
      "RAM: 15.951824188232422 GB\n",
      "\n",
      "--- Benchmarking 2 models ---\n",
      "\n",
      "\n",
      "##########\n",
      "# SILERO #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: SILERO ---\n",
      "\n",
      "CPU time top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "               model_inference        67.40%     495.547ms       100.00%     735.214ms     735.214ms           0 b    -532.88 Kb             1            --  \n",
      "                       forward         2.41%      17.704ms        32.04%     235.528ms     235.528ms     530.72 Kb     -55.99 Mb             1            --  \n",
      "                  aten::linear         0.58%       4.290ms        13.89%     102.085ms       1.595ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "                   aten::addmm        12.29%      90.370ms        12.98%      95.395ms       1.491ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::conv1d         0.20%       1.507ms         5.95%      43.745ms       1.823ms      10.56 Mb     -10.57 Mb            24            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 735.214ms\n",
      "\n",
      "CPU memory usage top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::empty         0.09%     659.000us         0.09%     659.000us       2.690us      73.66 Mb      73.66 Mb           245            --  \n",
      "              aten::empty_like         0.16%       1.161ms         0.19%       1.422ms      14.364us      40.00 Mb       2.65 Mb            99            --  \n",
      "                   aten::clone         0.32%       2.375ms         1.26%       9.229ms      94.173us      39.34 Mb      -1.59 Mb            98            --  \n",
      "                   aten::addmm        12.29%      90.370ms        12.98%      95.395ms       1.491ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::linear         0.58%       4.290ms        13.89%     102.085ms       1.595ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 735.214ms\n",
      "\n",
      "MFLOPs top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::addmm        12.29%      90.370ms        12.98%      95.395ms       1.491ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                     aten::bmm         2.04%      15.009ms         2.04%      15.009ms     469.031us      11.97 Mb      11.97 Mb            32      1506.296  \n",
      "                     aten::add         0.65%       4.795ms         0.65%       4.795ms      65.685us     -14.33 Mb     -14.33 Mb            73         9.058  \n",
      "                     aten::mul         0.42%       3.086ms         0.43%       3.158ms      46.441us      14.57 Mb      14.57 Mb            68         7.188  \n",
      "               model_inference        67.40%     495.547ms       100.00%     735.214ms     735.214ms           0 b    -532.88 Kb             1            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 735.214ms\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 1482.874\n",
      "Self CPU time total [ms]: 735.214\n",
      "CPU memory usage [Mb]: 352.66118907928467\n",
      "Self CPU memory usage [Mb]: 0.0\n",
      "MFLOPs: 11765.032691999999\n",
      "\n",
      "--- Psutil memory_full_info: SILERO ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 477.65625\n",
      "Std RSS: 1.9140625\n",
      "Mean USS [Mb]: 427.628125\n",
      "Std USS: 1.7125\n",
      "\n",
      "--- Timeit default_timer: SILERO ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 194.01092000771314\n",
      "Std inference time: 4.79055647613845\n",
      "\n",
      "--- Overall results: SILERO ---\n",
      "\n",
      "Mean memory usage [Mb]: 301.7615704413061\n",
      "Samples per CPU second: 705100.8277861956\n",
      "Samples per inference second: 2672014.5442297286\n",
      "\n",
      "##########\n",
      "# HuBERT #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: HuBERT ---\n",
      "\n",
      "CPU time top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference         6.56%     276.453ms       100.00%        4.216s        4.216s      32.00 Mb      -2.79 Gb             1            --  \n",
      "                    aten::linear         0.14%       5.797ms        61.24%        2.582s      17.684ms     456.95 Mb           0 b           146            --  \n",
      "                     aten::addmm        59.77%        2.520s        60.98%        2.571s      17.607ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                    aten::conv1d         0.00%      80.000us        12.27%     517.278ms      64.660ms     136.04 Mb           0 b             8            --  \n",
      "               aten::convolution         0.00%     112.000us        12.27%     517.198ms      64.650ms     136.04 Mb           0 b             8            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.216s\n",
      "\n",
      "CPU memory usage top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::empty         0.10%       4.214ms         0.10%       4.214ms      13.954us     878.47 Mb     878.47 Mb           302            --  \n",
      "                       aten::add         1.57%      66.272ms         1.57%      66.272ms     828.400us     528.74 Mb     528.74 Mb            80       138.605  \n",
      "                aten::empty_like         0.01%     531.000us         0.08%       3.221ms      28.504us     503.05 Mb           0 b           113            --  \n",
      "                       aten::bmm         6.28%     264.634ms         6.28%     264.643ms       5.513ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                     aten::clone         0.02%     954.000us         3.56%     149.866ms       1.362ms     471.04 Mb           0 b           110            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.216s\n",
      "\n",
      "MFLOPs top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::addmm        59.77%        2.520s        60.98%        2.571s      17.607ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                       aten::bmm         6.28%     264.634ms         6.28%     264.643ms       5.513ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                       aten::add         1.57%      66.272ms         1.57%      66.272ms     828.400us     528.74 Mb     528.74 Mb            80       138.605  \n",
      "                       aten::mul         0.20%       8.401ms         0.21%       9.022ms     360.880us      50.53 Mb      50.53 Mb            25        13.247  \n",
      "                 model_inference         6.56%     276.453ms       100.00%        4.216s        4.216s      32.00 Mb      -2.79 Gb             1            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.216s\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 13008.181\n",
      "Self CPU time total [ms]: 4215.627\n",
      "CPU memory usage [Mb]: 6604.42915058136\n",
      "Self CPU memory usage [Mb]: 32.0\n",
      "MFLOPs: 354856.833954\n",
      "\n",
      "--- Psutil memory_full_info: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 1711.21953125\n",
      "Std RSS: 0.5260684811647625\n",
      "Mean USS [Mb]: 1664.171875\n",
      "Std USS: 0.31255858825786564\n",
      "\n",
      "--- Timeit default_timer: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 4238.771400006954\n",
      "Std inference time: 100.64623963639144\n",
      "\n",
      "--- Overall results: HuBERT ---\n",
      "\n",
      "Mean memory usage [Mb]: 1125.1325682414852\n",
      "Samples per CPU second: 122971.03135547807\n",
      "Samples per inference second: 122299.5889797571\n",
      "\n",
      "\n",
      "--- Benchmarking 2 models for 4 micro controllers ---\n",
      "\n",
      "\n",
      "#########\n",
      "# ESP32 #\n",
      "#########\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit RISC-V\n",
      "Memory [Mb]: 0.23\n",
      "CPU speed [GHz]: 0.24\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    11334.549166666668   |       2991.0016834522444      |        45736.26991045592         |           173319.8623284148            | 131200.68280056788 |   False    |\n",
      "| HuBERT |    64990.91625000001    |       65347.72575010721       |        7976.499331166145         |            7932.94631220046            | 489188.0731484718  |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "##########################\n",
      "# Raspberry Pi Zero v1.3 #\n",
      "##########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit ARM\n",
      "Memory [Mb]: 512\n",
      "CPU speed [GHz]: 1\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    2720.2918000000004   |       717.8404040285386       |        190567.79129356635        |           722166.0930350617            |  58.9378067268176  |    True    |\n",
      "| HuBERT |    15597.819900000002   |       15683.454180025728      |        33235.413879858934        |           33053.94296750192            | 219.75245473466506 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "#########################\n",
      "# Raspberry Pi 3 B v1.2 #\n",
      "#########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 1000\n",
      "CPU speed [GHz]: 1.2\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    2266.9098333333336   |       598.2003366904489       |        228681.34955227963        |           866599.3116420741            | 30.17615704413061  |    True    |\n",
      "| HuBERT |    12998.183250000002   |       13069.54515002144       |        39882.49665583073         |            39664.7315610023            | 112.51325682414853 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "##############################\n",
      "# Raspberry Pi 4 Model B 4Go #\n",
      "##############################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 4000\n",
      "CPU speed [GHz]: 1.5\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| SILERO |    1813.5278666666668   |       478.5602693523591       |        285851.6869403495         |           1083249.1395525925           | 7.544039261032652  |    True    |\n",
      "| HuBERT |    10398.546600000001   |       10455.636120017152      |        49853.120819788404        |           49580.91445125287            | 28.128314206037132 |    True    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# Register models and micro controllers #\n",
    "#########################################\n",
    "\n",
    "models: list[Model] = [create_silero_model, create_hubert_model]\n",
    "\n",
    "micro_controllers: list[MicroController] = [esp32, pi_zero, pi_3_b, pi_4_b]\n",
    "\n",
    "#########################\n",
    "# Set benchmark options #\n",
    "#########################\n",
    "\n",
    "benchmark_options: BenchmarkOptions = {\n",
    "    'cpu_speed_ghz': 3.7,\n",
    "    'target_sampling_rate_khz': 16,\n",
    "    'logfile_path': 'benchmark.txt'\n",
    "}\n",
    "\n",
    "#################\n",
    "# Run benchmark #\n",
    "#################\n",
    "\n",
    "benchmark(models, micro_controllers, benchmark_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
