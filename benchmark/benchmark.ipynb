{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Micro Controller Benchmark\n",
    "\n",
    "Benchmark PyTorch Models and generate Compatibility list for micro controllers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "\n",
    "# %pip install torch torchaudio omegaconf soundfile numpy prettytable transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moritz\\anaconda3\\envs\\hws\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import wave\n",
    "import platform\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from glob import glob\n",
    "from timeit import default_timer\n",
    "from typing import TypedDict, Callable\n",
    "from prettytable import PrettyTable\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from transformers import AutoProcessor, HubertForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "\n",
    "class Model(TypedDict):\n",
    "    name: str\n",
    "    num_inferred_samples: int\n",
    "    infer: Callable[[None], list[str]]\n",
    "    is_pytorch: bool\n",
    "\n",
    "class MicroController(TypedDict):\n",
    "    name: str\n",
    "    architecture: str\n",
    "    memory_mb: float\n",
    "    cpu_speed_ghz: float\n",
    "\n",
    "class ModelResults:\n",
    "    name: str\n",
    "    cpu_time_total_ms: float | None\n",
    "    mean_inference_time_ms: float\n",
    "    mean_memory_usage_mb: float\n",
    "    m_flops: float | None\n",
    "    samples_per_cpu_second: float | None\n",
    "    samples_per_inference_second: float\n",
    "\n",
    "class ModelMicroControllerResults:\n",
    "    model_name: str\n",
    "    estimated_cpu_time_total_ms: float | None\n",
    "    estimated_inference_time_ms: float\n",
    "    estimated_samples_per_cpu_second: float | None\n",
    "    estimated_samples_per_inference_second: float\n",
    "    memory_usage_percentage: float\n",
    "    compatible: bool\n",
    "\n",
    "class BenchmarkOptions:\n",
    "    cpu_speed_ghz: float\n",
    "    target_sampling_rate_khz: float\n",
    "    logfile_path: str\n",
    "\n",
    "Log = Callable[[str], None]\n",
    "\n",
    "CreateModel = Callable[[None], Model]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_mb(byte: int) -> int:\n",
    "    return byte / (1024 ** 2)\n",
    "\n",
    "def create_logger(logifle_path: str) -> Log:\n",
    "    def __log(msg: str):\n",
    "        with open(logifle_path, 'a') as f:\n",
    "            f.write(f'{msg}\\n' )\n",
    "        print(msg)\n",
    "    return __log\n",
    "\n",
    "def log_hash_comment(content: str, log: Log):\n",
    "    content_str = f'# {content} #'\n",
    "    num_hashes = len(content_str)\n",
    "    hashes = '#' * num_hashes\n",
    "    log(\n",
    "        f'{hashes}\\n'\n",
    "        f'{content_str}\\n'\n",
    "        f'{hashes}\\n'\n",
    "        '\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_pytorch_model(model: Model, log: Log, row_limit = 5, iterations = 5) -> ModelResults:\n",
    "\n",
    "    #####################\n",
    "    # Instantiate Model #\n",
    "    #####################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ########################\n",
    "    # Run PyTorch Profiler #\n",
    "    ########################\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], profile_memory=True, with_flops=True, record_shapes=True, with_stack=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            _out = model['infer']()\n",
    "\n",
    "    key_averages = prof.key_averages()\n",
    "    total_average = key_averages.total_average()\n",
    "\n",
    "    key_averages.table()\n",
    "\n",
    "    cpu_time_ms = total_average.cpu_time_total * 0.001\n",
    "    self_cpu_time_ms = total_average.self_cpu_time_total * 0.001\n",
    "    cpu_memory_usage_mb = byte_to_mb(total_average.cpu_memory_usage)\n",
    "    self_cpu_memory_usage_mb = byte_to_mb(total_average.self_cpu_memory_usage)\n",
    "    m_flops = total_average.flops * 0.000001\n",
    "\n",
    "    log(f'--- PyTorch Profile: {model_name} ---\\n')\n",
    "\n",
    "\n",
    "    log(\n",
    "        f'CPU time top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_time_total\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'CPU memory usage top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"cpu_memory_usage\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'MFLOPs top {row_limit}\\n'\n",
    "        f'{key_averages.table(sort_by=\"flops\", row_limit=row_limit)}'\n",
    "    )\n",
    "\n",
    "    log(\n",
    "        f'Total averages\\n'\n",
    "        f'CPU time total [ms]: {cpu_time_ms}\\n' \n",
    "        f'Self CPU time total [ms]: {self_cpu_time_ms}\\n'\n",
    "        f'CPU memory usage [Mb]: {cpu_memory_usage_mb}\\n'\n",
    "        f'Self CPU memory usage [Mb]: {self_cpu_memory_usage_mb}\\n'\n",
    "        f'MFLOPs: {m_flops}\\n'\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([cpu_memory_usage_mb, mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))\n",
    "    samples_per_cpu_second = num_samples / (self_cpu_time_ms * 0.001)\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': self_cpu_time_ms,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': m_flops,\n",
    "        'samples_per_cpu_second': samples_per_cpu_second,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per CPU second: {samples_per_cpu_second}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_unknown_model(model: Model, log: Log, iterations = 5) -> ModelResults:\n",
    "\n",
    "    #####################\n",
    "    # Instantiate Model #\n",
    "    #####################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    model_name = model['name']\n",
    "    infer = model['infer']\n",
    "    num_samples = model['num_inferred_samples']\n",
    "\n",
    "    log_hash_comment(model_name, log)\n",
    "\n",
    "    ###############################\n",
    "    # Run psutil memory_full_info #\n",
    "    ###############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    psutil_mem_rss_b: list[int] = []\n",
    "    psutil_mem_uss_b: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        memory_info = process.memory_full_info()\n",
    "        psutil_mem_rss_b.append(memory_info.rss)\n",
    "        psutil_mem_uss_b.append(memory_info.uss)\n",
    "        _out = infer()\n",
    "\n",
    "    psutil_mem_rss_b = np.array(psutil_mem_rss_b)\n",
    "    psutil_mem_uss_b = np.array(psutil_mem_uss_b)\n",
    "    mean_psutil_mem_rss_b = np.mean(psutil_mem_rss_b)\n",
    "    mean_psutil_mem_uss_b = np.mean(psutil_mem_uss_b)\n",
    "    std_psutil_mem_rss = np.std(psutil_mem_rss_b)\n",
    "    std_psutil_mem_uss = np.std(psutil_mem_uss_b)\n",
    "\n",
    "    log(f'--- Psutil memory_full_info: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean RSS [Mb]: {byte_to_mb(mean_psutil_mem_rss_b)}\\n'\n",
    "        f'Std RSS: {byte_to_mb(std_psutil_mem_rss)}\\n'\n",
    "        f'Mean USS [Mb]: {byte_to_mb(mean_psutil_mem_uss_b)}\\n'\n",
    "        f'Std USS: {byte_to_mb(std_psutil_mem_uss)}\\n'\n",
    "    )\n",
    "\n",
    "    ############################\n",
    "    # Run timeit default_timer #\n",
    "    ############################\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    inference_times_ms: list[int] = []\n",
    "    for _ in range(iterations):\n",
    "        start = default_timer()\n",
    "        _out = infer()\n",
    "        end = default_timer()\n",
    "        inference_times_ms.append((end - start) * 1000)\n",
    "    \n",
    "    inference_times_ms = np.array(inference_times_ms)\n",
    "    mean_inference_time_ms = np.mean(inference_times_ms)\n",
    "    std_inference_time = np.std(inference_times_ms)\n",
    "\n",
    "\n",
    "    log(f'--- Timeit default_timer: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Over {iterations} iterations\\n'\n",
    "        f'Mean inference time [ms]: {mean_inference_time_ms}\\n'\n",
    "        f'Std inference time: {std_inference_time}\\n'\n",
    "    )\n",
    "\n",
    "    #############################\n",
    "    # Calculate overall results #\n",
    "    #############################\n",
    "\n",
    "    mean_memory_usage_mb = byte_to_mb(np.mean(np.array([mean_psutil_mem_rss_b, mean_psutil_mem_uss_b])))\n",
    "    samples_per_inference_second = num_samples / (mean_inference_time_ms * 0.001)\n",
    "\n",
    "    results: ModelResults = {\n",
    "        'name': model_name,\n",
    "        'cpu_time_total_ms': None,\n",
    "        'mean_inference_time_ms': mean_inference_time_ms,\n",
    "        'mean_memory_usage_mb': mean_memory_usage_mb,\n",
    "        'm_flops': None,\n",
    "        'samples_per_cpu_second': None,\n",
    "        'samples_per_inference_second': samples_per_inference_second,\n",
    "    }\n",
    "\n",
    "    log(f'--- Overall results: {model_name} ---\\n')\n",
    "\n",
    "    log(\n",
    "        f'Mean memory usage [Mb]: {mean_memory_usage_mb}\\n'\n",
    "        f'Samples per inference second: {samples_per_inference_second}\\n'\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(create_model: CreateModel, log: Log) -> ModelResults:\n",
    "    # Instantiate model\n",
    "    model = create_model()\n",
    "    is_pythorch_model = model['is_pytorch']\n",
    "    # Benchmark based on model type\n",
    "    if is_pythorch_model:\n",
    "        results = benchmark_pytorch_model(model, log)\n",
    "    else:\n",
    "        results = benchmark_unknown_model(model, log)\n",
    "    # Delete model from memory before running next benchmark\n",
    "    del model\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model_micro_controller(model_results: ModelResults, micro_controller: MicroController, options: BenchmarkOptions) -> ModelMicroControllerResults:\n",
    "    controller_cpu_speed_ghz = micro_controller['cpu_speed_ghz']\n",
    "    benchmark_cpu_speed_ghz = options['cpu_speed_ghz']\n",
    "    cpu_time_factor = benchmark_cpu_speed_ghz / controller_cpu_speed_ghz\n",
    "\n",
    "    estimated_cpu_time_total_ms = model_results['cpu_time_total_ms'] * cpu_time_factor\n",
    "    estimated_inference_time_ms = model_results['mean_inference_time_ms'] * cpu_time_factor\n",
    "\n",
    "    estimated_samples_per_cpu_second = model_results['samples_per_cpu_second'] / cpu_time_factor\n",
    "    estimated_samples_per_inference_second = model_results['samples_per_inference_second'] / cpu_time_factor\n",
    "\n",
    "    memory_usage_percentage = (model_results['mean_memory_usage_mb'] / micro_controller['memory_mb']) * 100\n",
    "\n",
    "    target_sampling_rate_hz = options['target_sampling_rate_khz'] * 1000\n",
    "\n",
    "    compatible = (\n",
    "        # estimated_samples_per_cpu_second >= target_sampling_rate_hz \n",
    "        estimated_samples_per_inference_second >= target_sampling_rate_hz\n",
    "        and memory_usage_percentage <= 100\n",
    "    )\n",
    "\n",
    "    results: ModelMicroControllerResults = {\n",
    "        'model_name': model_results['name'],\n",
    "        'estimated_cpu_time_total_ms': estimated_cpu_time_total_ms,\n",
    "        'estimated_inference_time_ms': estimated_inference_time_ms,\n",
    "        'estimated_samples_per_cpu_second': estimated_samples_per_cpu_second,\n",
    "        'estimated_samples_per_inference_second': estimated_samples_per_inference_second,\n",
    "        'memory_usage_percentage': memory_usage_percentage,\n",
    "        'compatible': compatible,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(create_models: list[CreateModel], micro_controllers: list[MicroController], options: BenchmarkOptions):\n",
    "    ##################\n",
    "    # Create logfile #\n",
    "    ##################\n",
    "\n",
    "    logfile_path = options['logfile_path']\n",
    "    f = open(logfile_path, 'w')\n",
    "    f.close()\n",
    "\n",
    "    log = create_logger(logfile_path)\n",
    "\n",
    "    ###################\n",
    "    # Log system info #\n",
    "    ###################\n",
    "\n",
    "    machine = platform.machine()\n",
    "    system = platform.system()\n",
    "    version = platform.version()\n",
    "    processor = platform.processor()\n",
    "    ram = psutil.virtual_memory().total / (1024.0 **3)\n",
    "\n",
    "    log(\n",
    "        f'--- Running benchmark on ---\\n'\n",
    "        '\\n'\n",
    "        f'Arch: {machine}\\n'\n",
    "        f'Platform: {system} {version}\\n'\n",
    "        f'CPU: {processor}, {options[\"cpu_speed_ghz\"]} GHz\\n'\n",
    "        f'RAM: {ram} GB\\n'\n",
    "    )\n",
    "\n",
    "\n",
    "    ###############################\n",
    "    # Benchmark individual models #\n",
    "    ###############################\n",
    "\n",
    "    log(\n",
    "        f'--- Benchmarking {len(create_models)} models ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "    models_results = [benchmark_model(create_model, log) for create_model in create_models]\n",
    "\n",
    "    ##########################################\n",
    "    # Benchmark models for micro controllers #\n",
    "    ##########################################\n",
    "\n",
    "    log(\n",
    "        f'\\n--- Benchmarking {len(create_models)} models for {len(micro_controllers)} micro controllers ---\\n'\n",
    "        '\\n'\n",
    "    )\n",
    "\n",
    "    for micro_controller in micro_controllers:\n",
    "        log_hash_comment(micro_controller['name'], log)\n",
    "        log(\n",
    "            'Info\\n'\n",
    "            f'Architecture: {micro_controller[\"architecture\"]}\\n'\n",
    "            f'Memory [Mb]: {micro_controller[\"memory_mb\"]}\\n'\n",
    "            f'CPU speed [GHz]: {micro_controller[\"cpu_speed_ghz\"]}\\n'\n",
    "        )\n",
    "        table = PrettyTable(\n",
    "            ['Model', 'Estimated CPU time [ms]', 'Estimated inference time [ms]', 'Estimated samples per CPU second', 'Estimated samples per inference second', 'Memory usage %', 'COMPATIBLE']\n",
    "        )\n",
    "        results = [benchmark_model_micro_controller(model_result, micro_controller, options).values() for model_result in models_results]\n",
    "        table.add_rows(results)\n",
    "        log(table.get_string())\n",
    "        log('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret PyTorch Profiler results\n",
    "\n",
    "References:\n",
    "- [Recipe](https://h-huang.github.io/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "\n",
    "#### CPU time\n",
    "\n",
    "CPU time vs self CPU time: operators can call other operators -> self cpu time excludes time spent in children operator calls, while total cpu time includes it\n",
    "\n",
    "#### Memory usage\n",
    "\n",
    "- Shows amount of memory used by the model’s tensors:\n",
    "- That was allocated (or released) during the execution of the model’s operators\n",
    "\n",
    "Self memory: corresponds to the memory allocated (released) by the operator, excluding the children calls to the other operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Silero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Moritz/.cache\\torch\\hub\\snakers4_silero-models_master\n",
      "100%|██████████| 0.99M/0.99M [00:00<00:00, 1.17MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Input statistics ---\n",
      "Sampling rate: 48000 Hz\n",
      "Number of samples: 518400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Use Silero utils to download model and test file #\n",
    "####################################################\n",
    "\n",
    "# Always use CPU (simulate run on micro controller)\n",
    "device = torch.device('cpu')  \n",
    "\n",
    "# Download model, decoder and utils\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device\n",
    ")\n",
    "(read_batch, split_into_batches, _ , prepare_model_input) = utils  # see function signature for details\n",
    "\n",
    "# Download a single test file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav',\n",
    "                            dst ='speech_orig.wav', progress=True)\n",
    "test_files = glob('speech_orig.wav')\n",
    "\n",
    "######################################\n",
    "# Get number of samples in test data #\n",
    "######################################\n",
    "\n",
    "audio_file = wave.open(test_files[0], 'r')\n",
    "sampling_rate = audio_file.getframerate()\n",
    "num_samples = audio_file.getnframes()\n",
    "\n",
    "print(\n",
    "    f'\\n--- Input statistics ---\\n'\n",
    "    f'Sampling rate: {sampling_rate} Hz\\n'\n",
    "    f'Number of samples: {num_samples}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the boch canoe slit on the smooth planks blew the sheet to the dark blue background it's easy to tell a depth of a well four hours of steady work faced us\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create SILERO model #\n",
    "#######################\n",
    "\n",
    "def create_silero_model():\n",
    "    # Prepare input data\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "    input = prepare_model_input(read_batch(batches[0]),\n",
    "                                device=device)\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_silero():\n",
    "        output = model(input)\n",
    "        return [decoder(example.cpu()) for example in output]\n",
    "\n",
    "    silero_model: Model = {\n",
    "        'name': 'Silero',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_silero,\n",
    "        'is_pytorch': True,\n",
    "    }\n",
    "\n",
    "    return silero_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "silero_model = create_silero_model()\n",
    "transcription = silero_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del silero_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuBERT\n",
    "\n",
    "Reference: [Hugging Face](https://huggingface.co/docs/transformers/model_doc/hubert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"THE BIRCH CANOE SLID ON THE SMOOTH PLANKS GLUE THE SHEET TO THE DARK BLUE BACKGROUND IT'S EASY TO TELL THE DEPTH OF A WELL FOUR HOURS OF STEADY WORK FACED US\"]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Create HuBERT model #\n",
    "#######################\n",
    "\n",
    "def create_hubert_model():\n",
    "    # Download model\n",
    "    model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "    # Prepare inputs\n",
    "    batches = split_into_batches(test_files, batch_size=10)\n",
    "    inputs = processor(read_batch(batches[0])[0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "\n",
    "    #################################\n",
    "    # Create model for benchmarking #\n",
    "    #################################\n",
    "\n",
    "    def infer_hubert():\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        return processor.batch_decode(predicted_ids)\n",
    "\n",
    "    hubert_model: Model = {\n",
    "        'name': 'HuBERT',\n",
    "        'num_inferred_samples': num_samples,\n",
    "        'infer': infer_hubert,\n",
    "        'is_pytorch': True,\n",
    "    }\n",
    "\n",
    "    return hubert_model\n",
    "\n",
    "#######################################\n",
    "# Run model inference and log results #\n",
    "#######################################\n",
    "\n",
    "hubert_model = create_hubert_model()\n",
    "transcription = hubert_model['infer']()\n",
    "print(transcription)\n",
    "\n",
    "del hubert_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro Controllers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "esp32: MicroController = {\n",
    "    'name': 'ESP32',\n",
    "    'architecture': '32-bit RISC-V',\n",
    "    'cpu_speed_ghz': 0.24,\n",
    "    'memory_mb': 0.23,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_zero: MicroController = {\n",
    "    'name': 'Raspberry Pi Zero v1.3',\n",
    "    'architecture': '32-bit ARM',\n",
    "    'cpu_speed_ghz': 1,\n",
    "    'memory_mb': 512,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_3_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 3 B v1.2',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.2,\n",
    "    'memory_mb': 1000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raspberry Pi 4 Model B 4Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Create micro controller for benchmarking #\n",
    "############################################\n",
    "\n",
    "pi_4_b: MicroController = {\n",
    "    'name': 'Raspberry Pi 4 Model B 4Go',\n",
    "    'architecture': '64-bit ARM',\n",
    "    'cpu_speed_ghz': 1.5,\n",
    "    'memory_mb': 4000,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running benchmark on ---\n",
      "\n",
      "Arch: AMD64\n",
      "Platform: Windows 10.0.22621\n",
      "CPU: AMD64 Family 23 Model 8 Stepping 2, AuthenticAMD, 3.7 GHz\n",
      "RAM: 15.951824188232422 GB\n",
      "\n",
      "--- Benchmarking 2 models ---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "# Silero #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: Silero ---\n",
      "\n",
      "CPU time top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "               model_inference        68.36%     616.848ms       100.00%     902.288ms     902.288ms           0 b    -532.84 Kb             1            --  \n",
      "                       forward         2.55%      22.998ms        31.22%     281.678ms     281.678ms     530.72 Kb     -54.14 Mb             1            --  \n",
      "                  aten::linear         0.68%       6.147ms        12.71%     114.656ms       1.792ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "                   aten::addmm        11.08%      99.985ms        11.66%     105.235ms       1.644ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::conv1d         0.20%       1.773ms         5.70%      51.442ms       2.143ms      10.56 Mb     -10.57 Mb            24            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 902.288ms\n",
      "\n",
      "CPU memory usage top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::empty         0.11%       1.002ms         0.11%       1.002ms       4.090us      74.46 Mb      74.46 Mb           245            --  \n",
      "              aten::empty_like         0.18%       1.597ms         0.23%       2.039ms      20.596us      40.00 Mb     814.00 Kb            99            --  \n",
      "                   aten::clone         0.34%       3.043ms         1.34%      12.068ms     123.143us      39.34 Mb    -542.00 Kb            98            --  \n",
      "                   aten::addmm        11.08%      99.985ms        11.66%     105.235ms       1.644ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                  aten::linear         0.68%       6.147ms        12.71%     114.656ms       1.792ms      31.80 Mb      -6.36 Mb            64            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 902.288ms\n",
      "\n",
      "MFLOPs top 5\n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::addmm        11.08%      99.985ms        11.66%     105.235ms       1.644ms      38.16 Mb      38.16 Mb            64     10242.490  \n",
      "                     aten::bmm         2.04%      18.384ms         2.04%      18.385ms     574.531us      11.97 Mb      11.97 Mb            32      1506.296  \n",
      "                     aten::add         0.61%       5.548ms         0.61%       5.548ms      76.000us     -14.60 Mb     -14.60 Mb            73         9.058  \n",
      "                     aten::mul         0.47%       4.261ms         0.51%       4.578ms      67.324us      14.04 Mb      14.04 Mb            68         7.188  \n",
      "               model_inference        68.36%     616.848ms       100.00%     902.288ms     902.288ms           0 b    -532.84 Kb             1            --  \n",
      "------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 902.288ms\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 1787.2\n",
      "Self CPU time total [ms]: 902.288\n",
      "CPU memory usage [Mb]: 351.74264907836914\n",
      "Self CPU memory usage [Mb]: 0.0\n",
      "MFLOPs: 11765.032691999999\n",
      "\n",
      "--- Psutil memory_full_info: Silero ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 477.6390625\n",
      "Std RSS: 1.6359375\n",
      "Mean USS [Mb]: 427.50625\n",
      "Std USS: 1.6281250000000003\n",
      "\n",
      "--- Timeit default_timer: Silero ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 199.07279999461025\n",
      "Std inference time: 2.295017988685782\n",
      "\n",
      "--- Overall results: Silero ---\n",
      "\n",
      "Mean memory usage [Mb]: 301.7152159826435\n",
      "Samples per CPU second: 574539.3931870977\n",
      "Samples per inference second: 2604072.4800878637\n",
      "\n",
      "##########\n",
      "# HuBERT #\n",
      "##########\n",
      "\n",
      "\n",
      "--- PyTorch Profile: HuBERT ---\n",
      "\n",
      "CPU time top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference         6.46%     270.450ms       100.00%        4.188s        4.188s      32.00 Mb      -2.79 Gb             1            --  \n",
      "                    aten::linear         0.14%       5.845ms        60.96%        2.553s      17.485ms     456.95 Mb           0 b           146            --  \n",
      "                     aten::addmm        59.57%        2.494s        60.70%        2.542s      17.409ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                    aten::conv1d         0.00%      87.000us        12.66%     530.108ms      66.263ms     136.04 Mb           0 b             8            --  \n",
      "               aten::convolution         0.00%     127.000us        12.66%     530.021ms      66.253ms     136.04 Mb           0 b             8            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.188s\n",
      "\n",
      "CPU memory usage top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::empty         0.10%       4.378ms         0.10%       4.378ms      14.497us     878.47 Mb     878.47 Mb           302            --  \n",
      "                       aten::add         1.54%      64.608ms         1.54%      64.608ms     807.600us     528.74 Mb     528.74 Mb            80       138.605  \n",
      "                aten::empty_like         0.01%     532.000us         0.08%       3.267ms      28.912us     503.05 Mb       2.11 Mb           113            --  \n",
      "                       aten::bmm         6.27%     262.383ms         6.27%     262.390ms       5.466ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                     aten::clone         0.02%     977.000us         3.66%     153.085ms       1.392ms     471.04 Mb      -2.11 Mb           110            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.188s\n",
      "\n",
      "MFLOPs top 5\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  Total MFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::addmm        59.57%        2.494s        60.70%        2.542s      17.409ms     456.95 Mb     456.95 Mb           146    326145.606  \n",
      "                       aten::bmm         6.27%     262.383ms         6.27%     262.390ms       5.466ms     476.10 Mb     476.10 Mb            48     28559.376  \n",
      "                       aten::add         1.54%      64.608ms         1.54%      64.608ms     807.600us     528.74 Mb     528.74 Mb            80       138.605  \n",
      "                       aten::mul         0.20%       8.320ms         0.21%       8.934ms     357.360us      50.53 Mb      50.53 Mb            25        13.247  \n",
      "                 model_inference         6.46%     270.450ms       100.00%        4.188s        4.188s      32.00 Mb      -2.79 Gb             1            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.188s\n",
      "\n",
      "Total averages\n",
      "CPU time total [ms]: 12969.84\n",
      "Self CPU time total [ms]: 4187.581\n",
      "CPU memory usage [Mb]: 6604.44558429718\n",
      "Self CPU memory usage [Mb]: 32.0\n",
      "MFLOPs: 354856.833954\n",
      "\n",
      "--- Psutil memory_full_info: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean RSS [Mb]: 1712.89765625\n",
      "Std RSS: 0.4312500000000001\n",
      "Mean USS [Mb]: 1665.79140625\n",
      "Std USS: 0.23164556539841205\n",
      "\n",
      "--- Timeit default_timer: HuBERT ---\n",
      "\n",
      "Over 5 iterations\n",
      "Mean inference time [ms]: 4168.25843998231\n",
      "Std inference time: 66.64736261954846\n",
      "\n",
      "--- Overall results: HuBERT ---\n",
      "\n",
      "Mean memory usage [Mb]: 1126.2317869967092\n",
      "Samples per CPU second: 123794.62033092615\n",
      "Samples per inference second: 124368.488054258\n",
      "\n",
      "\n",
      "--- Benchmarking 2 models for 4 micro controllers ---\n",
      "\n",
      "\n",
      "#########\n",
      "# ESP32 #\n",
      "#########\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit RISC-V\n",
      "Memory [Mb]: 0.23\n",
      "CPU speed [GHz]: 0.24\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Silero |    13910.273333333334   |       3069.0389999169083      |        37267.420098622555        |           168912.80951921278           | 131180.52868810584 |   False    |\n",
      "| HuBERT |    64558.54041666667    |       64260.650949727285      |        8029.9213187627765        |           8067.145171087005            | 489665.9943463953  |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "##########################\n",
      "# Raspberry Pi Zero v1.3 #\n",
      "##########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 32-bit ARM\n",
      "Memory [Mb]: 512\n",
      "CPU speed [GHz]: 1\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Silero |        3338.4656        |       736.5693599800579       |        155280.91707759397        |           703803.3729967199            | 58.92875312161006  |    True    |\n",
      "| HuBERT |    15494.049700000001   |       15422.556227934547      |         33458.0054948449         |           33613.104879529186           | 219.96714589779475 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "#########################\n",
      "# Raspberry Pi 3 B v1.2 #\n",
      "#########################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 1000\n",
      "CPU speed [GHz]: 1.2\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %   | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "| Silero |    2782.054666666667    |       613.8077999833816       |        186337.10049311278        |           844564.0475960639            | 30.17152159826435  |    True    |\n",
      "| HuBERT |    12911.708083333335   |       12852.130189945456      |        40149.606593813885        |           40335.72585543503            | 112.62317869967092 |   False    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "##############################\n",
      "# Raspberry Pi 4 Model B 4Go #\n",
      "##############################\n",
      "\n",
      "\n",
      "Info\n",
      "Architecture: 64-bit ARM\n",
      "Memory [Mb]: 4000\n",
      "CPU speed [GHz]: 1.5\n",
      "\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| Model  | Estimated CPU time [ms] | Estimated inference time [ms] | Estimated samples per CPU second | Estimated samples per inference second |   Memory usage %  | COMPATIBLE |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "| Silero |    2225.6437333333333   |       491.0462399867053       |        232921.37561639096        |           1055705.0594950798           | 7.542880399566087 |    True    |\n",
      "| HuBERT |    10329.366466666668   |       10281.704151956365      |        50187.00824226735         |           50419.65731929379            | 28.15579467491773 |    True    |\n",
      "+--------+-------------------------+-------------------------------+----------------------------------+----------------------------------------+-------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# Register models and micro controllers #\n",
    "#########################################\n",
    "\n",
    "models: list[Model] = [create_silero_model, create_hubert_model]\n",
    "\n",
    "micro_controllers: list[MicroController] = [esp32, pi_zero, pi_3_b, pi_4_b]\n",
    "\n",
    "#########################\n",
    "# Set benchmark options #\n",
    "#########################\n",
    "\n",
    "benchmark_options: BenchmarkOptions = {\n",
    "    'cpu_speed_ghz': 3.7,\n",
    "    'target_sampling_rate_khz': 16,\n",
    "    'logfile_path': 'benchmark.txt'\n",
    "}\n",
    "\n",
    "#################\n",
    "# Run benchmark #\n",
    "#################\n",
    "\n",
    "benchmark(models, micro_controllers, benchmark_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
